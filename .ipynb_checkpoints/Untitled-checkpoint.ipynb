{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6acaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reading input file to pandas Dataframe---\n",
      "data/churnsimulateddata.csv\n",
      "Shape of original data: (706693, 19)\n",
      "---Select features---\n",
      "[1 2 0]\n",
      "---Simulating clients based on geographical locations of the banks---\n",
      "Number of 6 clients. \n",
      "Index(['Age', 'Total_score'], dtype='object')\n",
      "Index(['Age', 'Total_score'], dtype='object')\n",
      "Index(['Age', 'Total_score'], dtype='object')\n",
      "Index(['Age', 'Total_score'], dtype='object')\n",
      "Index(['Age', 'Total_score'], dtype='object')\n",
      "Index(['Age', 'Total_score'], dtype='object')\n",
      "---Training local models at local clients---\n",
      "client No 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_16076/161511515.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.4515747089999991\n",
      "Accuracy:  0.7164094843808807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.46      0.52      4762\n",
      "           1       0.79      0.93      0.86     19263\n",
      "           2       0.49      0.36      0.42      7859\n",
      "\n",
      "    accuracy                           0.72     31884\n",
      "   macro avg       0.63      0.58      0.60     31884\n",
      "weighted avg       0.69      0.72      0.70     31884\n",
      "\n",
      "client No 1\n",
      "The training time is : 0.5688301250000052\n",
      "Accuracy:  0.725025541352072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.35      0.49      5610\n",
      "           1       0.79      0.91      0.85     23709\n",
      "           2       0.53      0.52      0.53     10812\n",
      "\n",
      "    accuracy                           0.73     40131\n",
      "   macro avg       0.71      0.59      0.62     40131\n",
      "weighted avg       0.72      0.73      0.71     40131\n",
      "\n",
      "client No 2\n",
      "The training time is : 0.3663896250000107\n",
      "Accuracy:  0.6952164009111618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.00      0.01      3446\n",
      "           1       0.79      0.92      0.85     15971\n",
      "           2       0.47      0.53      0.50      6923\n",
      "\n",
      "    accuracy                           0.70     26340\n",
      "   macro avg       0.70      0.48      0.45     26340\n",
      "weighted avg       0.71      0.70      0.65     26340\n",
      "\n",
      "client No 3\n",
      "The training time is : 0.2747910410000003\n",
      "Accuracy:  0.7050665782639924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.27      0.41      2502\n",
      "           1       0.77      0.90      0.83     10693\n",
      "           2       0.50      0.50      0.50      4904\n",
      "\n",
      "    accuracy                           0.71     18099\n",
      "   macro avg       0.72      0.56      0.58     18099\n",
      "weighted avg       0.71      0.71      0.68     18099\n",
      "\n",
      "client No 4\n",
      "The training time is : 0.18111045799999204\n",
      "Accuracy:  0.6988541666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.31      0.45      1457\n",
      "           1       0.77      0.89      0.83      5471\n",
      "           2       0.51      0.51      0.51      2672\n",
      "\n",
      "    accuracy                           0.70      9600\n",
      "   macro avg       0.69      0.57      0.60      9600\n",
      "weighted avg       0.70      0.70      0.68      9600\n",
      "\n",
      "client No 5\n",
      "The training time is : 0.2397942909999955\n",
      "Accuracy:  0.6805991627420199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55      2685\n",
      "           1       0.75      0.88      0.81      8162\n",
      "           2       0.52      0.43      0.47      4441\n",
      "\n",
      "    accuracy                           0.68     15288\n",
      "   macro avg       0.64      0.60      0.61     15288\n",
      "weighted avg       0.66      0.68      0.67     15288\n",
      "\n",
      "---Aggregating at the aggregation server---\n",
      "---Constructing model---\n",
      "---Testing on local clients---\n",
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.28      0.41      4762\n",
      "           1       0.80      0.92      0.86     19263\n",
      "           2       0.48      0.48      0.48      7859\n",
      "\n",
      "    accuracy                           0.72     31884\n",
      "   macro avg       0.67      0.56      0.58     31884\n",
      "weighted avg       0.71      0.72      0.70     31884\n",
      "\n",
      "client No 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.40      0.52      5610\n",
      "           1       0.79      0.91      0.85     23709\n",
      "           2       0.54      0.50      0.52     10812\n",
      "\n",
      "    accuracy                           0.73     40131\n",
      "   macro avg       0.69      0.60      0.63     40131\n",
      "weighted avg       0.72      0.73      0.71     40131\n",
      "\n",
      "client No 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.41      0.52      3446\n",
      "           1       0.79      0.91      0.85     15971\n",
      "           2       0.54      0.47      0.51      6923\n",
      "\n",
      "    accuracy                           0.73     26340\n",
      "   macro avg       0.69      0.60      0.62     26340\n",
      "weighted avg       0.72      0.73      0.72     26340\n",
      "\n",
      "client No 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.40      0.52      2502\n",
      "           1       0.77      0.90      0.83     10693\n",
      "           2       0.52      0.46      0.49      4904\n",
      "\n",
      "    accuracy                           0.71     18099\n",
      "   macro avg       0.68      0.59      0.62     18099\n",
      "weighted avg       0.70      0.71      0.70     18099\n",
      "\n",
      "client No 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.49      0.59      1457\n",
      "           1       0.77      0.90      0.83      5471\n",
      "           2       0.54      0.46      0.50      2672\n",
      "\n",
      "    accuracy                           0.71      9600\n",
      "   macro avg       0.69      0.62      0.64      9600\n",
      "weighted avg       0.70      0.71      0.70      9600\n",
      "\n",
      "client No 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.44      0.54      2685\n",
      "           1       0.74      0.89      0.81      8162\n",
      "           2       0.52      0.44      0.48      4441\n",
      "\n",
      "    accuracy                           0.68     15288\n",
      "   macro avg       0.66      0.59      0.61     15288\n",
      "weighted avg       0.67      0.68      0.66     15288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#from audioop import mul\n",
    "#from multiprocessing.context import assert_spawning\n",
    "import os\n",
    "#from statistics import mode\n",
    "import timeit\n",
    "#from bitarray import test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sympy import N\n",
    "\n",
    "\n",
    "print(\"---Reading input file to pandas Dataframe---\")\n",
    "# dataset path\n",
    "path = 'data'\n",
    "file_name = 'churnsimulateddata.csv'\n",
    "file = os.path.join(path, file_name)\n",
    "print(file)\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f'Shape of original data: {df.shape}')\n",
    "\n",
    "print(\"---Select features---\")\n",
    "#feature_names = ['Age','Tenure','PSYTE_Segment','Total_score','Trnx_count','num_products', 'Churn_risk']\n",
    "feature_names = ['Age','PSYTE_Segment','Total_score','Churn_risk']\n",
    "#feature_names = ['PSYTE_Segment','Total_score','Churn_risk']\n",
    "\n",
    "selected_df = df[feature_names]\n",
    "\n",
    "selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
    "\n",
    "print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "selected_df = selected_df.dropna()\n",
    "#selected_df = selected_df.drop(selected_df[(selected_df.Churn_risk != 0) or (selected_df.Churn_risk != 1) (selected_df.Churn_risk != 2)].index)\n",
    "#print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "\n",
    "print('---Simulating clients based on geographical locations of the banks---') \n",
    "geo_split = 'T'\n",
    "if geo_split:\n",
    "    selected_df_v2 = selected_df.sample(frac=1)\n",
    "    clients_data = []\n",
    "    for i in range(0, 60, 10):\n",
    "        clients_data.append(selected_df_v2[(selected_df_v2.PSYTE_Segment >= i) & (selected_df_v2.PSYTE_Segment < i+10)]) \n",
    "    \n",
    "else:\n",
    "    n_clients = 10\n",
    "    clients_data = np.array_split(selected_df.sample(frac=1), n_clients)\n",
    "    \n",
    "print(f'Number of {np.size(clients_data)} clients. ')\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i, client_data in enumerate(clients_data):\n",
    "    X = client_data.drop(columns=['Churn_risk','PSYTE_Segment'])\n",
    "    print(X.columns)\n",
    "    y = client_data['Churn_risk']\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42) \n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE(random_state=27, ratio=1.0)\n",
    "    _X_train, _y_train = sm.fit_sample(_X_train, _y_train)\n",
    "\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "\n",
    "\n",
    "class LR_ScikitModel():\n",
    "    def __init__(self):\n",
    "        self.name = 'LR'\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        clf = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
    "        starttime = timeit.default_timer()\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        model_params = clf.get_params() \n",
    "        training_time = timeit.default_timer() - starttime\n",
    "        print(\"The training time is :\", training_time)\n",
    "        #starttime = timeit.default_timer()\n",
    "        y_pred=clf.predict(X_test)\n",
    "        #precison = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        #print('Precison: ', precison)\n",
    "        #recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        #print('Recall: ', recall)\n",
    "        #f1 = metrics.f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        #print('F1: ', f1)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        #print('Intercept')\n",
    "        #print(clf.intercept_)\n",
    "        #print('Coefficients')\n",
    "        #print(clf.coef_)\n",
    "        \n",
    "        #testing_time = timeit.default_timer() - starttime\n",
    "        #print(\"The testing time is :\", testing_time)\n",
    "        return clf.intercept_, clf.coef_, accuracy\n",
    "\n",
    "\n",
    "print('---Training local models at local clients---')\n",
    "#Training Local model\n",
    "intercept_l = []\n",
    "coef_l = []\n",
    "accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "    intercept, coef, accuracy =  model.fit(X_train[i], X_test[i], y_train[i], y_test[i])\n",
    "    intercept_l.append(intercept)\n",
    "    coef_l.append(coef)\n",
    "    accuracy_l.append(accuracy)\n",
    "#print(intercept_l)\n",
    "#print(coef_l)\n",
    "#print(accuracy_l)\n",
    "\n",
    "\n",
    "print('---Aggregating at the aggregation server---')\n",
    "#averaged the local weights\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Constructing model---')\n",
    "#averaged the local weights\n",
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Testing on local clients---')\n",
    "#\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9f815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))': /simple/imbalanced-learn/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))': /simple/imbalanced-learn/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))': /simple/imbalanced-learn/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))': /simple/imbalanced-learn/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))': /simple/imbalanced-learn/\u001b[0m\n",
      "Could not fetch URL https://pypi.org/simple/imbalanced-learn/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/imbalanced-learn/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))) - skipping\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement imbalanced-learn (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for imbalanced-learn\u001b[0m\n",
      "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)'))) - skipping\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84786d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba869a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
