{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2769b322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reading input file to pandas Dataframe---\n",
      "data/churnsimulateddata.csv\n",
      "Shape of original data: (706693, 19)\n",
      "---Select features---\n",
      "[1 0]\n",
      "---Simulating clients based on geographical locations of the banks---\n",
      "Number of 6 clients. \n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(127535, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_41404/1301323787.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:8870: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_41404/1301323787.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127535, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(160520, 5)\n",
      "(160520, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(105359, 5)\n",
      "(105359, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(72392, 5)\n",
      "(72392, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(38397, 5)\n",
      "(38397, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(61148, 5)\n",
      "(61148, 5)\n",
      "---Training local models at local clients---\n",
      "client No 0\n",
      "The training time is : 1.2816628750000518\n",
      "Accuracy:  0.8334274244134989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79     12555\n",
      "           1       0.86      0.86      0.86     19329\n",
      "\n",
      "    accuracy                           0.83     31884\n",
      "   macro avg       0.83      0.83      0.83     31884\n",
      "weighted avg       0.83      0.83      0.83     31884\n",
      "\n",
      "client No 1\n",
      "The training time is : 0.8641456250000488\n",
      "Accuracy:  0.8316264234631582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80     16532\n",
      "           1       0.86      0.85      0.86     23599\n",
      "\n",
      "    accuracy                           0.83     40131\n",
      "   macro avg       0.83      0.83      0.83     40131\n",
      "weighted avg       0.83      0.83      0.83     40131\n",
      "\n",
      "client No 2\n",
      "The training time is : 0.6248426660000064\n",
      "Accuracy:  0.8223614274867123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78     10557\n",
      "           1       0.85      0.85      0.85     15783\n",
      "\n",
      "    accuracy                           0.82     26340\n",
      "   macro avg       0.81      0.82      0.82     26340\n",
      "weighted avg       0.82      0.82      0.82     26340\n",
      "\n",
      "client No 3\n",
      "The training time is : 0.5281299170000011\n",
      "Accuracy:  0.8198795513564285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      7444\n",
      "           1       0.85      0.85      0.85     10655\n",
      "\n",
      "    accuracy                           0.82     18099\n",
      "   macro avg       0.81      0.81      0.81     18099\n",
      "weighted avg       0.82      0.82      0.82     18099\n",
      "\n",
      "client No 4\n",
      "The training time is : 0.6662870409999755\n",
      "Accuracy:  0.8195833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4236\n",
      "           1       0.85      0.83      0.84      5364\n",
      "\n",
      "    accuracy                           0.82      9600\n",
      "   macro avg       0.82      0.82      0.82      9600\n",
      "weighted avg       0.82      0.82      0.82      9600\n",
      "\n",
      "client No 5\n",
      "The training time is : 0.5292689170000244\n",
      "Accuracy:  0.8096546310832025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      7152\n",
      "           1       0.84      0.80      0.82      8136\n",
      "\n",
      "    accuracy                           0.81     15288\n",
      "   macro avg       0.81      0.81      0.81     15288\n",
      "weighted avg       0.81      0.81      0.81     15288\n",
      "\n",
      "---Aggregating at the aggregation server---\n",
      "---Constructing model---\n",
      "[-17.04847218]\n",
      "[[-1.00538977e-01  2.79191745e-01  9.59428405e-01  1.74130413e-03\n",
      "   2.87031140e+00]]\n",
      "---Testing on local clients---\n",
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.57     12555\n",
      "           1       0.00      0.00      0.00     19329\n",
      "\n",
      "    accuracy                           0.39     31884\n",
      "   macro avg       0.20      0.50      0.28     31884\n",
      "weighted avg       0.16      0.39      0.22     31884\n",
      "\n",
      "client No 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58     16532\n",
      "           1       0.00      0.00      0.00     23599\n",
      "\n",
      "    accuracy                           0.41     40131\n",
      "   macro avg       0.21      0.50      0.29     40131\n",
      "weighted avg       0.17      0.41      0.24     40131\n",
      "\n",
      "client No 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57     10557\n",
      "           1       0.00      0.00      0.00     15783\n",
      "\n",
      "    accuracy                           0.40     26340\n",
      "   macro avg       0.20      0.50      0.29     26340\n",
      "weighted avg       0.16      0.40      0.23     26340\n",
      "\n",
      "client No 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58      7444\n",
      "           1       0.00      0.00      0.00     10655\n",
      "\n",
      "    accuracy                           0.41     18099\n",
      "   macro avg       0.21      0.50      0.29     18099\n",
      "weighted avg       0.17      0.41      0.24     18099\n",
      "\n",
      "client No 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61      4236\n",
      "           1       0.00      0.00      0.00      5364\n",
      "\n",
      "    accuracy                           0.44      9600\n",
      "   macro avg       0.22      0.50      0.31      9600\n",
      "weighted avg       0.19      0.44      0.27      9600\n",
      "\n",
      "client No 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64      7152\n",
      "           1       0.00      0.00      0.00      8136\n",
      "\n",
      "    accuracy                           0.47     15288\n",
      "   macro avg       0.23      0.50      0.32     15288\n",
      "weighted avg       0.22      0.47      0.30     15288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#from audioop import mul\n",
    "#from multiprocessing.context import assert_spawning\n",
    "import os\n",
    "#from statistics import mode\n",
    "import timeit\n",
    "#from bitarray import test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sympy import N\n",
    "\n",
    "\n",
    "print(\"---Reading input file to pandas Dataframe---\")\n",
    "# dataset path\n",
    "path = 'data'\n",
    "file_name = 'churnsimulateddata.csv'\n",
    "file = os.path.join(path, file_name)\n",
    "print(file)\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f'Shape of original data: {df.shape}')\n",
    "\n",
    "print(\"---Select features---\")\n",
    "feature_names = ['Age','Tenure','PSYTE_Segment','Total_score','Trnx_count','num_products', 'Churn_risk']\n",
    "#feature_names = ['Age','PSYTE_Segment','Total_score','Churn_risk']\n",
    "#feature_names = ['PSYTE_Segment','Total_score','Churn_risk']\n",
    "\n",
    "selected_df = df[feature_names]\n",
    "\n",
    "selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'  \n",
    "\n",
    "selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
    "\n",
    "print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "selected_df = selected_df.dropna()\n",
    "#selected_df = selected_df.drop(selected_df[(selected_df.Churn_risk != 0) or (selected_df.Churn_risk != 1) (selected_df.Churn_risk != 2)].index)\n",
    "#print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "\n",
    "print('---Simulating clients based on geographical locations of the banks---') \n",
    "geo_split = 'T'\n",
    "if geo_split:\n",
    "    selected_df_v2 = selected_df.sample(frac=1)\n",
    "    clients_data = []\n",
    "    for i in range(0, 60, 10):\n",
    "        clients_data.append(selected_df_v2[(selected_df_v2.PSYTE_Segment >= i) & (selected_df_v2.PSYTE_Segment < i+10)]) \n",
    "    \n",
    "else:\n",
    "    n_clients = 10\n",
    "    clients_data = np.array_split(selected_df.sample(frac=1), n_clients)\n",
    "    \n",
    "print(f'Number of {np.size(clients_data)} clients. ')\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i, client_data in enumerate(clients_data):\n",
    "    X = client_data.drop(columns=['Churn_risk','PSYTE_Segment'])\n",
    "    print(X.columns)\n",
    "    y = client_data['Churn_risk']\n",
    "    \n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42) \n",
    "    print(np.shape(_X_train))\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "    #_X_train, _y_train = SMOTE().fit_resample(_X_train, _y_train)\n",
    "    #_X_train, _y_train = ADASYN().fit_resample(_X_train, _y_train)\n",
    "\n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "\n",
    "\n",
    "class LR_ScikitModel():\n",
    "    def __init__(self):\n",
    "        self.name = 'LR'\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        clf = LogisticRegression(multi_class='auto', max_iter=1000, n_jobs=-1)\n",
    "        starttime = timeit.default_timer()\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        model_params = clf.get_params() \n",
    "        training_time = timeit.default_timer() - starttime\n",
    "        print(\"The training time is :\", training_time)\n",
    "        #starttime = timeit.default_timer()\n",
    "        y_pred=clf.predict(X_test)\n",
    "        #precison = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        #print('Precison: ', precison)\n",
    "        #recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        #print('Recall: ', recall)\n",
    "        #f1 = metrics.f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        #print('F1: ', f1)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        #print('Intercept')\n",
    "        #print(clf.intercept_)\n",
    "        #print('Coefficients')\n",
    "        #print(clf.coef_)\n",
    "        \n",
    "        #testing_time = timeit.default_timer() - starttime\n",
    "        #print(\"The testing time is :\", testing_time)\n",
    "        return clf.intercept_, clf.coef_, accuracy\n",
    "\n",
    "\n",
    "print('---Training local models at local clients---')\n",
    "#Training Local model\n",
    "intercept_l = []\n",
    "coef_l = []\n",
    "accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "    intercept, coef, accuracy =  model.fit(X_train[i], X_test[i], y_train[i], y_test[i])\n",
    "    intercept_l.append(intercept)\n",
    "    coef_l.append(coef)\n",
    "    accuracy_l.append(accuracy)\n",
    "#print(intercept_l)\n",
    "#print(coef_l)\n",
    "#print(accuracy_l)\n",
    "\n",
    "\n",
    "print('---Aggregating at the aggregation server---')\n",
    "#averaged the local weights\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Constructing model---')\n",
    "#averaged the local weights\n",
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "print(global_intercept)\n",
    "print(global_coef)   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Testing on local clients---')\n",
    "#\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064ec090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "471ac6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.02300370e-01,  2.79518880e-01,  9.59302175e-01,\n",
       "          1.81650129e-03,  2.87066376e+00]]),\n",
       " array([-16.99110949]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(global_coef), np.array(global_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c74dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "Global model Accuracy:  38.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56     12416\n",
      "           1       0.00      0.00      0.00     19468\n",
      "\n",
      "    accuracy                           0.39     31884\n",
      "   macro avg       0.19      0.50      0.28     31884\n",
      "weighted avg       0.15      0.39      0.22     31884\n",
      "\n",
      "client No 1\n",
      "Global model Accuracy:  41.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59     16660\n",
      "           1       0.00      0.00      0.00     23471\n",
      "\n",
      "    accuracy                           0.42     40131\n",
      "   macro avg       0.21      0.50      0.29     40131\n",
      "weighted avg       0.17      0.42      0.24     40131\n",
      "\n",
      "client No 2\n",
      "Global model Accuracy:  39.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57     10423\n",
      "           1       0.00      0.00      0.00     15917\n",
      "\n",
      "    accuracy                           0.40     26340\n",
      "   macro avg       0.20      0.50      0.28     26340\n",
      "weighted avg       0.16      0.40      0.22     26340\n",
      "\n",
      "client No 3\n",
      "Global model Accuracy:  40.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58      7394\n",
      "           1       0.00      0.00      0.00     10705\n",
      "\n",
      "    accuracy                           0.41     18099\n",
      "   macro avg       0.20      0.50      0.29     18099\n",
      "weighted avg       0.17      0.41      0.24     18099\n",
      "\n",
      "client No 4\n",
      "Global model Accuracy:  44.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61      4234\n",
      "           1       0.00      0.00      0.00      5366\n",
      "\n",
      "    accuracy                           0.44      9600\n",
      "   macro avg       0.22      0.50      0.31      9600\n",
      "weighted avg       0.19      0.44      0.27      9600\n",
      "\n",
      "client No 5\n",
      "Global model Accuracy:  46.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63      7081\n",
      "           1       0.00      0.00      0.00      8207\n",
      "\n",
      "    accuracy                           0.46     15288\n",
      "   macro avg       0.23      0.50      0.32     15288\n",
      "weighted avg       0.21      0.46      0.29     15288\n",
      "\n",
      "[0.8356228829506963, 0.8313024843637089, 0.8246013667425968, 0.8189955246146196, 0.8189583333333333, 0.815018315018315] 0.8240831511705449\n",
      "[38.94, 41.51, 39.57, 40.85, 44.1, 46.32] 41.88166666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "gl_m_accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    gl_m_accuracy = round(accuracy_score(y_test[i], label)*100,2)\n",
    "    print('Global model Accuracy: ', gl_m_accuracy)\n",
    "    gl_m_accuracy_l.append(gl_m_accuracy)\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "    \n",
    "    \n",
    "print(accuracy_l, np.mean(accuracy_l))\n",
    "print(gl_m_accuracy_l, np.mean(gl_m_accuracy_l))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.loc[df.Churn_risk[df.Churn_risk == 'Medium'],df.Churn_risk] =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82501f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa0f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ufunc:\n",
      "\n",
      "multiply = <ufunc 'multiply'>\n",
      "    multiply(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n",
      "    \n",
      "    Multiply arguments element-wise.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x1, x2 : array_like\n",
      "        Input arrays to be multiplied.\n",
      "        If ``x1.shape != x2.shape``, they must be broadcastable to a common\n",
      "        shape (which becomes the shape of the output).\n",
      "    out : ndarray, None, or tuple of ndarray and None, optional\n",
      "        A location into which the result is stored. If provided, it must have\n",
      "        a shape that the inputs broadcast to. If not provided or None,\n",
      "        a freshly-allocated array is returned. A tuple (possible only as a\n",
      "        keyword argument) must have length equal to the number of outputs.\n",
      "    where : array_like, optional\n",
      "        This condition is broadcast over the input. At locations where the\n",
      "        condition is True, the `out` array will be set to the ufunc result.\n",
      "        Elsewhere, the `out` array will retain its original value.\n",
      "        Note that if an uninitialized `out` array is created via the default\n",
      "        ``out=None``, locations within it where the condition is False will\n",
      "        remain uninitialized.\n",
      "    **kwargs\n",
      "        For other keyword-only arguments, see the\n",
      "        :ref:`ufunc docs <ufuncs.kwargs>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    y : ndarray\n",
      "        The product of `x1` and `x2`, element-wise.\n",
      "        This is a scalar if both `x1` and `x2` are scalars.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Equivalent to `x1` * `x2` in terms of array broadcasting.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.multiply(2.0, 4.0)\n",
      "    8.0\n",
      "    \n",
      "    >>> x1 = np.arange(9.0).reshape((3, 3))\n",
      "    >>> x2 = np.arange(3.0)\n",
      "    >>> np.multiply(x1, x2)\n",
      "    array([[  0.,   1.,   4.],\n",
      "           [  0.,   4.,  10.],\n",
      "           [  0.,   7.,  16.]])\n",
      "    \n",
      "    The ``*`` operator can be used as a shorthand for ``np.multiply`` on\n",
      "    ndarrays.\n",
      "    \n",
      "    >>> x1 = np.arange(9.0).reshape((3, 3))\n",
      "    >>> x2 = np.arange(3.0)\n",
      "    >>> x1 * x2\n",
      "    array([[  0.,   1.,   4.],\n",
      "           [  0.,   4.,  10.],\n",
      "           [  0.,   7.,  16.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "help(\n",
    "    np.multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bf1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reading input file to pandas Dataframe---\n",
      "data/churnsimulateddata.csv\n",
      "Shape of original data: (706693, 19)\n",
      "---Select features---\n",
      "[1 2 0]\n",
      "---Simulating clients based on geographical locations of the banks---\n",
      "Number of 6 clients. \n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 0 2]\n",
      "(127535, 6)\n",
      "(127535, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[0 1 2]\n",
      "(160520, 6)\n",
      "(160520, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 2 0]\n",
      "(105359, 6)\n",
      "(105359, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[0 1 2]\n",
      "(72392, 6)\n",
      "(72392, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 2 0]\n",
      "(38397, 6)\n",
      "(38397, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 0 2]\n",
      "(61148, 6)\n",
      "(61148, 6)\n",
      "---Training local models at local clients---\n",
      "client No 0\n",
      "[1 0 2] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "68903    29      14    32.000000         177             3   928.000000\n",
      "8056     58      22    17.166667         210             6   995.666667\n",
      "281076   74      16    14.000000          40             5  1036.000000\n",
      "543145   71      30    27.833333         108             8  1976.166667\n",
      "570772   31      21    14.166667          56             4   439.166667\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "137942   45      18    16.500000          67             1   742.500000\n",
      "381836   39       3    20.166667          75             2   786.500000\n",
      "385952   37       9    26.833333         539             2   992.833333\n",
      "52604    83      31    23.166667           6             2  1922.833333\n",
      "295452   35      17     0.000000           2             1     0.000000\n",
      "\n",
      "[127535 rows x 6 columns]\n",
      "68903     1\n",
      "8056      1\n",
      "281076    1\n",
      "543145    1\n",
      "570772    1\n",
      "         ..\n",
      "137942    1\n",
      "381836    1\n",
      "385952    1\n",
      "52604     1\n",
      "295452    0\n",
      "Name: Churn_risk, Length: 127535, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 1.4623351249992993\n",
      "Accuracy:  70.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.10      0.18      4676\n",
      "           1       0.81      0.93      0.86     19362\n",
      "           2       0.45      0.53      0.49      7846\n",
      "\n",
      "    accuracy                           0.71     31884\n",
      "   macro avg       0.70      0.52      0.51     31884\n",
      "weighted avg       0.72      0.71      0.67     31884\n",
      "\n",
      "client No 1\n",
      "[1 2 0] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "534294   55      24    33.666667           4             2  1851.666667\n",
      "514073   39       6    22.166667         117             1   864.500000\n",
      "568516   58       2     4.333333         183             1   251.333333\n",
      "340513   71       0     7.666667           3             1   544.333333\n",
      "323787   51       1     1.333333           7             2    68.000000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "579729   46       3     6.000000         679             1   276.000000\n",
      "35782    72      18    19.500000          30             1  1404.000000\n",
      "433618   74      19    45.333333         292             7  3354.666667\n",
      "97399    68      40    34.833333          21             1  2368.666667\n",
      "206611   29      18    36.500000         133             2  1058.500000\n",
      "\n",
      "[160520 rows x 6 columns]\n",
      "534294    1\n",
      "514073    1\n",
      "568516    2\n",
      "340513    0\n",
      "323787    0\n",
      "         ..\n",
      "579729    1\n",
      "35782     1\n",
      "433618    1\n",
      "97399     1\n",
      "206611    1\n",
      "Name: Churn_risk, Length: 160520, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.8829113749998214\n",
      "Accuracy:  66.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5667\n",
      "           1       0.74      0.94      0.83     23537\n",
      "           2       0.45      0.41      0.43     10927\n",
      "\n",
      "    accuracy                           0.67     40131\n",
      "   macro avg       0.40      0.45      0.42     40131\n",
      "weighted avg       0.56      0.67      0.60     40131\n",
      "\n",
      "client No 2\n",
      "[1 2 0] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "74245    46      24    40.666667          55             2  1870.666667\n",
      "542116   56       1    36.666667           4             2  2053.333333\n",
      "619110   59      33    13.833333         626             2   816.166667\n",
      "213302   22       1     0.000000         195             2     0.000000\n",
      "201687   49       6    30.833333          28             2  1510.833333\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "31885    20       3    21.833333          65             1   436.666667\n",
      "209571   38       4     8.000000          62             1   304.000000\n",
      "7741     58       3    20.833333          66             3  1208.333333\n",
      "541085   32      22    47.500000          65             1  1520.000000\n",
      "26618    46       3    25.166667         124             2  1157.666667\n",
      "\n",
      "[105359 rows x 6 columns]\n",
      "74245     1\n",
      "542116    1\n",
      "619110    1\n",
      "213302    2\n",
      "201687    1\n",
      "         ..\n",
      "31885     1\n",
      "209571    2\n",
      "7741      1\n",
      "541085    1\n",
      "26618     1\n",
      "Name: Churn_risk, Length: 105359, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.7275706669997817\n",
      "Accuracy:  67.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3534\n",
      "           1       0.74      0.95      0.83     15827\n",
      "           2       0.44      0.37      0.40      6979\n",
      "\n",
      "    accuracy                           0.67     26340\n",
      "   macro avg       0.39      0.44      0.41     26340\n",
      "weighted avg       0.56      0.67      0.61     26340\n",
      "\n",
      "client No 3\n",
      "[1 0 2] [0 1 2]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "105331   54      39    55.166667          50             4  2979.000000\n",
      "283655   50       0    12.666667          17             2   633.333333\n",
      "219105   68       9     8.166667          27             1   555.333333\n",
      "276929   50      15    13.166667           4             1   658.333333\n",
      "203305   65      20    34.000000          11             4  2210.000000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "566444   27       3     9.000000          19             1   243.000000\n",
      "569270   73      39     8.500000        1294             4   620.500000\n",
      "488091   27      20    22.666667         110             2   612.000000\n",
      "598488   56       5    14.166667         443             2   793.333333\n",
      "340559   60      27    13.666667           1             1   820.000000\n",
      "\n",
      "[72392 rows x 6 columns]\n",
      "105331    1\n",
      "283655    1\n",
      "219105    1\n",
      "276929    1\n",
      "203305    1\n",
      "         ..\n",
      "566444    1\n",
      "569270    1\n",
      "488091    1\n",
      "598488    2\n",
      "340559    0\n",
      "Name: Churn_risk, Length: 72392, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.619735166999817\n",
      "Accuracy:  66.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2436\n",
      "           1       0.74      0.94      0.83     10768\n",
      "           2       0.44      0.39      0.41      4895\n",
      "\n",
      "    accuracy                           0.67     18099\n",
      "   macro avg       0.39      0.44      0.41     18099\n",
      "weighted avg       0.56      0.67      0.60     18099\n",
      "\n",
      "client No 4\n",
      "[2 0 1] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "222826   40       6     1.833333          57             2    73.333333\n",
      "296873   65      21     1.500000          13             2    97.500000\n",
      "180392   24      11    32.500000          84             2   780.000000\n",
      "30011    50      31    25.166667         121             5  1258.333333\n",
      "704439   39       7     7.166667          42             1   279.500000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "379378   66       2    14.833333           3             2   979.000000\n",
      "684081   68      20     0.000000         130             1     0.000000\n",
      "693571   45       3     7.000000          37             1   315.000000\n",
      "346174   29       1     0.000000           8             1     0.000000\n",
      "688494   47      17    10.500000           3             2   493.500000\n",
      "\n",
      "[38397 rows x 6 columns]\n",
      "222826    2\n",
      "296873    0\n",
      "180392    1\n",
      "30011     1\n",
      "704439    0\n",
      "         ..\n",
      "379378    1\n",
      "684081    2\n",
      "693571    2\n",
      "346174    0\n",
      "688494    2\n",
      "Name: Churn_risk, Length: 38397, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.5119907500002228\n",
      "Accuracy:  63.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1537\n",
      "           1       0.70      0.94      0.80      5299\n",
      "           2       0.43      0.39      0.41      2764\n",
      "\n",
      "    accuracy                           0.63      9600\n",
      "   macro avg       0.38      0.44      0.41      9600\n",
      "weighted avg       0.51      0.63      0.56      9600\n",
      "\n",
      "client No 5\n",
      "[2 1 0] [1 0 2]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "577658   87      45    12.166667          12             2  1058.500000\n",
      "222903   27      23     7.666667         137             3   207.000000\n",
      "587310   38      13     1.500000         283             1    57.000000\n",
      "39158    35       2    22.833333         100             2   799.166667\n",
      "607866   50       0     0.500000         163             1    25.000000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "219650   40       4     8.666667          87             2   346.666667\n",
      "252959   67      17     2.333333          60             2   156.333333\n",
      "74631    31      12    44.000000          50             5  1364.000000\n",
      "157239   31       2    18.833333          49             1   583.833333\n",
      "3496     55      21    19.000000          40             3  1045.000000\n",
      "\n",
      "[61148 rows x 6 columns]\n",
      "577658    2\n",
      "222903    1\n",
      "587310    1\n",
      "39158     1\n",
      "607866    2\n",
      "         ..\n",
      "219650    1\n",
      "252959    1\n",
      "74631     1\n",
      "157239    2\n",
      "3496      1\n",
      "Name: Churn_risk, Length: 61148, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.724646916999518\n",
      "Accuracy:  64.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.26      0.39      2729\n",
      "           1       0.69      0.93      0.79      8061\n",
      "           2       0.48      0.38      0.42      4498\n",
      "\n",
      "    accuracy                           0.65     15288\n",
      "   macro avg       0.65      0.52      0.54     15288\n",
      "weighted avg       0.65      0.65      0.61     15288\n",
      "\n",
      "[array([ 0.00022204, -0.00036875,  0.00014671]), array([ 6.34492089e-05, -1.27139667e-04,  6.36904577e-05]), array([ 4.94228878e-05, -1.07728907e-04,  5.83060191e-05]), array([ 7.96757407e-05, -1.59013683e-04,  7.93379421e-05]), array([ 7.03996921e-05, -1.39526366e-04,  6.91266736e-05]), array([ 9.67864203e-05, -1.69083973e-04,  7.22975531e-05])]\n",
      "[array([[ 1.23649509e-02,  7.77695958e-04, -8.57747894e-04,\n",
      "        -4.74196027e-03,  8.99774481e-05, -1.86673072e-03],\n",
      "       [-2.28737437e-02, -1.43591828e-03,  2.50138534e-03,\n",
      "         2.81603643e-03, -1.04581328e-05,  2.38883231e-03],\n",
      "       [ 1.05087928e-02,  6.58222325e-04, -1.64363745e-03,\n",
      "         1.92592384e-03, -7.95193153e-05, -5.22101590e-04]]), array([[ 3.68308116e-03,  3.14160873e-04, -3.14655414e-04,\n",
      "        -1.46445961e-03,  2.92704641e-05, -2.54693037e-03],\n",
      "       [-8.10568356e-03, -6.84264952e-04,  8.93590257e-04,\n",
      "         6.09709634e-04, -4.33342786e-07,  2.17761518e-03],\n",
      "       [ 4.42260240e-03,  3.70104079e-04, -5.78934843e-04,\n",
      "         8.54749980e-04, -2.88371213e-05,  3.69315185e-04]]), array([[ 3.21000556e-03,  2.55406800e-04, -3.25028071e-04,\n",
      "        -2.05579641e-03,  1.29676693e-05, -2.16453763e-03],\n",
      "       [-7.55163876e-03, -6.47636287e-04,  9.45335730e-04,\n",
      "         1.05043742e-03,  1.58993578e-05,  1.94118626e-03],\n",
      "       [ 4.34163320e-03,  3.92229487e-04, -6.20307659e-04,\n",
      "         1.00535899e-03, -2.88670271e-05,  2.23351368e-04]]), array([[ 5.11476240e-03,  3.54937306e-04, -4.90847221e-04,\n",
      "        -1.89150935e-03,  3.05294687e-05, -2.50379541e-03],\n",
      "       [-1.12130227e-02, -8.54662349e-04,  1.37746273e-03,\n",
      "         1.04471579e-03,  9.35880649e-06,  2.32327142e-03],\n",
      "       [ 6.09826026e-03,  4.99725043e-04, -8.86615505e-04,\n",
      "         8.46793558e-04, -3.98882752e-05,  1.80523992e-04]]), array([[ 4.11620654e-03,  2.60212670e-04, -3.36434140e-04,\n",
      "        -7.00664146e-04,  3.51154450e-05, -2.65445971e-03],\n",
      "       [-8.97995937e-03, -5.41330939e-04,  9.56001948e-04,\n",
      "         2.05328227e-04,  5.09293911e-07,  2.36071958e-03],\n",
      "       [ 4.86375283e-03,  2.81118269e-04, -6.19567808e-04,\n",
      "         4.95335919e-04, -3.56247389e-05,  2.93740124e-04]]), array([[ 5.44104397e-03,  4.15874492e-04, -4.57262634e-04,\n",
      "         3.54366594e-05,  5.05411200e-05, -2.90858011e-03],\n",
      "       [-1.07400622e-02, -8.70150511e-04,  1.33303214e-03,\n",
      "        -9.26670187e-05,  1.89785648e-06,  2.51427736e-03],\n",
      "       [ 5.29901828e-03,  4.54276019e-04, -8.75769503e-04,\n",
      "         5.72303593e-05, -5.24389764e-05,  3.94302748e-04]])]\n",
      "[70.64, 66.63, 67.12, 66.66, 63.12, 64.7]\n",
      "---Aggregating at the aggregation server---\n",
      "---Constructing model---\n",
      "---Testing on local clients---\n",
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "Global model Accuracy:  67.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4676\n",
      "           1       0.77      0.95      0.85     19362\n",
      "           2       0.41      0.41      0.41      7846\n",
      "\n",
      "    accuracy                           0.68     31884\n",
      "   macro avg       0.39      0.45      0.42     31884\n",
      "weighted avg       0.57      0.68      0.62     31884\n",
      "\n",
      "client No 1\n",
      "Global model Accuracy:  67.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5667\n",
      "           1       0.76      0.94      0.84     23537\n",
      "           2       0.46      0.46      0.46     10927\n",
      "\n",
      "    accuracy                           0.68     40131\n",
      "   macro avg       0.41      0.47      0.43     40131\n",
      "weighted avg       0.57      0.68      0.62     40131\n",
      "\n",
      "client No 2\n",
      "Global model Accuracy:  68.08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3534\n",
      "           1       0.76      0.94      0.84     15827\n",
      "           2       0.45      0.44      0.45      6979\n",
      "\n",
      "    accuracy                           0.68     26340\n",
      "   macro avg       0.40      0.46      0.43     26340\n",
      "weighted avg       0.58      0.68      0.62     26340\n",
      "\n",
      "client No 3\n",
      "Global model Accuracy:  66.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2436\n",
      "           1       0.74      0.94      0.83     10768\n",
      "           2       0.44      0.41      0.42      4895\n",
      "\n",
      "    accuracy                           0.67     18099\n",
      "   macro avg       0.39      0.45      0.42     18099\n",
      "weighted avg       0.56      0.67      0.61     18099\n",
      "\n",
      "client No 4\n",
      "Global model Accuracy:  64.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1537\n",
      "           1       0.72      0.93      0.81      5299\n",
      "           2       0.45      0.44      0.44      2764\n",
      "\n",
      "    accuracy                           0.64      9600\n",
      "   macro avg       0.39      0.46      0.42      9600\n",
      "weighted avg       0.53      0.64      0.58      9600\n",
      "\n",
      "client No 5\n",
      "Global model Accuracy:  61.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2729\n",
      "           1       0.70      0.93      0.80      8061\n",
      "           2       0.43      0.43      0.43      4498\n",
      "\n",
      "    accuracy                           0.62     15288\n",
      "   macro avg       0.37      0.45      0.41     15288\n",
      "weighted avg       0.49      0.62      0.55     15288\n",
      "\n",
      "[70.64, 66.63, 67.12, 66.66, 63.12, 64.7] 66.47833333333332\n",
      "[67.88, 67.77, 68.08, 66.73, 64.15, 61.56] 66.02833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#from audioop import mul\n",
    "#from multiprocessing.context import assert_spawning\n",
    "import os\n",
    "#from statistics import mode\n",
    "import timeit\n",
    "#from bitarray import test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sympy import N\n",
    "\n",
    "\n",
    "print(\"---Reading input file to pandas Dataframe---\")\n",
    "# dataset path\n",
    "path = 'data'\n",
    "file_name = 'churnsimulateddata.csv'\n",
    "file = os.path.join(path, file_name)\n",
    "print(file)\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f'Shape of original data: {df.shape}')\n",
    "\n",
    "print(\"---Select features---\")\n",
    "feature_names = ['Age','Tenure','PSYTE_Segment','Total_score','Trnx_count','num_products', 'Churn_risk']\n",
    "#feature_names = ['Age','PSYTE_Segment','Total_score','Churn_risk']\n",
    "#feature_names = ['PSYTE_Segment','Total_score','Churn_risk']\n",
    "\n",
    "selected_df = df[feature_names].dropna()\n",
    "\n",
    "\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'  \n",
    "\n",
    "selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
    "selected_df['A'] = selected_df.Age * selected_df.Total_score\n",
    "#selected_df['B'] = selected_df.Churn_risk * selected_df.Total_score\n",
    "\n",
    "\n",
    "#print(selected_df['Churn_risk'][selected_df['Churn_risk_code'] == 0]) #HIGH\n",
    "#print(selected_df['Churn_risk'][selected_df['Churn_risk_code'] == 1]) #LOW\n",
    "#print(selected_df['Churn_risk'][selected_df['Churn_risk_code'] == 2]) #MED\n",
    "\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = '1'\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Low'] = '0'\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'High'] = '2'\n",
    "\n",
    "\n",
    "print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "selected_df = selected_df.dropna()\n",
    "#selected_df = selected_df.drop(selected_df[(selected_df.Churn_risk != 0) or (selected_df.Churn_risk != 1) (selected_df.Churn_risk != 2)].index)\n",
    "#print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "classes = np.unique(selected_df['Churn_risk'])\n",
    "class_labels = {c:i for i,c in enumerate(classes)}\n",
    "def one_hot(y):\n",
    "    return np.eye(len(classes))[np.vectorize(lambda c: class_labels[c])(y).reshape(-1)]\n",
    "\n",
    "print('---Simulating clients based on geographical locations of the banks---') \n",
    "geo_split = 'T'\n",
    "if geo_split:\n",
    "    selected_df_v2 = selected_df.sample(frac=1)\n",
    "    clients_data = []\n",
    "    for i in range(0, 60, 10):\n",
    "        y = selected_df_v2[(selected_df_v2.PSYTE_Segment >= i) & (selected_df_v2.PSYTE_Segment < i+10)]\n",
    "        clients_data.append(y) \n",
    "    \n",
    "else:\n",
    "    n_clients = 10\n",
    "    clients_data = np.array_split(selected_df.sample(frac=1), n_clients)\n",
    "    \n",
    "print(f'Number of {np.size(clients_data)} clients. ')\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i, client_data in enumerate(clients_data):\n",
    "    X = client_data.drop(columns=['Churn_risk','PSYTE_Segment'])\n",
    "    print(X.columns)\n",
    "    y = client_data['Churn_risk']\n",
    "    print(y.unique())\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42) \n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # downsample majority\n",
    "    # concatenate our training data back together\n",
    "    X = pd.concat([_X_train, _y_train], axis=1)\n",
    "    low = X[X.Churn_risk==1]\n",
    "    high = X[X.Churn_risk==0]\n",
    "    medium = X[X.Churn_risk==2]\n",
    "    \n",
    "    X.Churn_risk.value_counts()\n",
    "\n",
    "    low_downsampled = resample(low,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(medium), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "    # combine minority and downsampled majority\n",
    "    downsampled = pd.concat([low_downsampled, high, medium])\n",
    "\n",
    "    # checking counts\n",
    "    downsampled.Churn_risk.value_counts()\n",
    "\n",
    "    _X_train = downsampled.drop('Churn_risk', axis=1)\n",
    "    _y_train = downsampled.Churn_risk\n",
    "    '''\n",
    "\n",
    "    #oversamppling\n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "    #_X_train, _y_train = SMOTE().fit_resample(_X_train, _y_train)\n",
    "    #_X_train, _y_train = ADASYN().fit_resample(_X_train, _y_train)\n",
    "\n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "\n",
    "\n",
    "class LR_ScikitModel():\n",
    "    def __init__(self):\n",
    "        self.name = 'LR'\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        clf = LogisticRegression(multi_class='multinomial', max_iter=10, n_jobs=-1)\n",
    "        #clf = LogisticRegression(multi_class='auto', max_iter=500, n_jobs=-1)\n",
    "        \n",
    "        starttime = timeit.default_timer()\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        print(X_train)\n",
    "        print(y_train)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        model_params = clf.get_params() \n",
    "        training_time = timeit.default_timer() - starttime\n",
    "        print(\"The training time is :\", training_time)\n",
    "        #starttime = timeit.default_timer()\n",
    "        y_pred=clf.predict(X_test)\n",
    "        #precison = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        #print('Precison: ', precison)\n",
    "        #recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        #print('Recall: ', recall)\n",
    "        #f1 = metrics.f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        #print('F1: ', f1)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,2)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        #print('Intercept')\n",
    "        #print(clf.intercept_)\n",
    "        #print('Coefficients')\n",
    "        #print(clf.coef_)\n",
    "        \n",
    "        #testing_time = timeit.default_timer() - starttime\n",
    "        #print(\"The testing time is :\", testing_time)\n",
    "        return clf.intercept_, clf.coef_, accuracy\n",
    "\n",
    "\n",
    "print('---Training local models at local clients---')\n",
    "#Training Local model\n",
    "intercept_l = []\n",
    "coef_l = []\n",
    "row_l = []\n",
    "accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "    print(y_train[i].unique(), y_test[i].unique())\n",
    "    intercept, coef, accuracy =  model.fit(X_train[i], X_test[i], y_train[i], y_test[i])\n",
    "    intercept_l.append(intercept)\n",
    "    coef_l.append(coef)\n",
    "    accuracy_l.append(accuracy)\n",
    "    row_l.append(np.size(accuracy))\n",
    "print(intercept_l)\n",
    "print(coef_l)\n",
    "print(accuracy_l)\n",
    "\n",
    "\n",
    "print('---Aggregating at the aggregation server---')\n",
    "#averaged the local weights\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Constructing model---')\n",
    "#averaged the local weights\n",
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "#print(np.shape(global_intercept))\n",
    "#print(np.shape(global_coef))   # axis1=3 becasue there is 3 classes\n",
    "#global_intercept = np.sum(intercept_l*row_l)/np.sum(row_l)\n",
    "#global_coef = np.sum(np.multiply(coef_l, row_l))/np.sum(row_l)\n",
    "#print(np.shape(global_intercept))\n",
    "#print(np.shape(global_coef))\n",
    "\n",
    "\n",
    "print('---Testing on local clients---')\n",
    "#\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "gl_m_accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    gl_m_accuracy = round(accuracy_score(y_test[i], label)*100,2)\n",
    "    print('Global model Accuracy: ', gl_m_accuracy)\n",
    "    gl_m_accuracy_l.append(gl_m_accuracy)\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "    \n",
    "    \n",
    "print(accuracy_l, np.mean(accuracy_l))\n",
    "print(gl_m_accuracy_l, np.mean(gl_m_accuracy_l))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca826f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "(6, 3, 6)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "print(np.shape(intercept_l))\n",
    "print(np.shape(coef_l))   # axis1=3 becasue there is 3 classes\n",
    "print(np.shape(row_l))\n",
    "#global_intercept = np.sum(intercept_l*row_l)/np.sum(row_l)\n",
    "#global_coef = np.sum(np.multiply(coef_l, row_l))/np.sum(row_l)\n",
    "#print(np.shape(global_intercept))\n",
    "#print(np.shape(global_coef))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ab1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "gl_m_accuracy = f1_score(y_test[i], label,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a04d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.79530237, 0.42728984])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_m_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "920d20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = [[0.71101752, 0.7836647 , 0.50746934], [0.71278725, 0.79218125, 0.517991  ], [0.69646681, 0.78045157, 0.50823673], [0.69844284, 0.77568922, 0.49197145], [0.68932331, 0.77653997, 0.4966818 ], [0.69084746, 0.77533719, 0.49375755]] \n",
    "b = [[0.7104107 , 0.78084087, 0.49949193], [0.7124484 , 0.7912401 , 0.51175971], [0.6972058 , 0.77861246, 0.50651141], [0.6998088 , 0.77641686, 0.49832999], [0.68797106, 0.77594184, 0.49982741], [0.69178547, 0.7714565 , 0.49356308]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b426a840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7104107, 0.78084087, 0.49949193],\n",
       " [0.7124484, 0.7912401, 0.51175971],\n",
       " [0.6972058, 0.77861246, 0.50651141],\n",
       " [0.6998088, 0.77641686, 0.49832999],\n",
       " [0.68797106, 0.77594184, 0.49982741],\n",
       " [0.69178547, 0.7714565, 0.49356308]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e0660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
