{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb9a3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reading input file to pandas Dataframe---\n",
      "data/churnsimulateddata.csv\n",
      "Shape of original data: (706693, 19)\n",
      "---Select features---\n",
      "[1 0]\n",
      "---Simulating clients based on geographical locations of the banks---\n",
      "Number of 6 clients. \n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(127535, 5)\n",
      "(127535, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_16076/1301323787.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:8870: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_16076/1301323787.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160520, 5)\n",
      "(160520, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(105359, 5)\n",
      "(105359, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(72392, 5)\n",
      "(72392, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(38397, 5)\n",
      "(38397, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(61148, 5)\n",
      "(61148, 5)\n",
      "---Training local models at local clients---\n",
      "client No 0\n",
      "The training time is : 1.3003066249993935\n",
      "Accuracy:  0.8356228829506963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79     12416\n",
      "           1       0.87      0.86      0.86     19468\n",
      "\n",
      "    accuracy                           0.84     31884\n",
      "   macro avg       0.83      0.83      0.83     31884\n",
      "weighted avg       0.84      0.84      0.84     31884\n",
      "\n",
      "client No 1\n",
      "The training time is : 0.8431952500004627\n",
      "Accuracy:  0.8313024843637089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80     16660\n",
      "           1       0.86      0.85      0.86     23471\n",
      "\n",
      "    accuracy                           0.83     40131\n",
      "   macro avg       0.83      0.83      0.83     40131\n",
      "weighted avg       0.83      0.83      0.83     40131\n",
      "\n",
      "client No 2\n",
      "The training time is : 0.6873056660006114\n",
      "Accuracy:  0.8246013667425968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78     10423\n",
      "           1       0.86      0.85      0.85     15917\n",
      "\n",
      "    accuracy                           0.82     26340\n",
      "   macro avg       0.82      0.82      0.82     26340\n",
      "weighted avg       0.82      0.82      0.82     26340\n",
      "\n",
      "client No 3\n",
      "The training time is : 0.5337175419999767\n",
      "Accuracy:  0.8189955246146196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      7394\n",
      "           1       0.85      0.85      0.85     10705\n",
      "\n",
      "    accuracy                           0.82     18099\n",
      "   macro avg       0.81      0.81      0.81     18099\n",
      "weighted avg       0.82      0.82      0.82     18099\n",
      "\n",
      "client No 4\n",
      "The training time is : 0.6516543340003409\n",
      "Accuracy:  0.8189583333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4234\n",
      "           1       0.84      0.83      0.84      5366\n",
      "\n",
      "    accuracy                           0.82      9600\n",
      "   macro avg       0.82      0.82      0.82      9600\n",
      "weighted avg       0.82      0.82      0.82      9600\n",
      "\n",
      "client No 5\n",
      "The training time is : 0.7260012910001024\n",
      "Accuracy:  0.815018315018315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      7081\n",
      "           1       0.84      0.80      0.82      8207\n",
      "\n",
      "    accuracy                           0.82     15288\n",
      "   macro avg       0.81      0.82      0.81     15288\n",
      "weighted avg       0.82      0.82      0.82     15288\n",
      "\n",
      "---Aggregating at the aggregation server---\n",
      "---Constructing model---\n",
      "[-16.99110949]\n",
      "[[-1.02300370e-01  2.79518880e-01  9.59302175e-01  1.81650129e-03\n",
      "   2.87066376e+00]]\n",
      "---Testing on local clients---\n",
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56     12416\n",
      "           1       0.00      0.00      0.00     19468\n",
      "\n",
      "    accuracy                           0.39     31884\n",
      "   macro avg       0.19      0.50      0.28     31884\n",
      "weighted avg       0.15      0.39      0.22     31884\n",
      "\n",
      "client No 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59     16660\n",
      "           1       0.00      0.00      0.00     23471\n",
      "\n",
      "    accuracy                           0.42     40131\n",
      "   macro avg       0.21      0.50      0.29     40131\n",
      "weighted avg       0.17      0.42      0.24     40131\n",
      "\n",
      "client No 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57     10423\n",
      "           1       0.00      0.00      0.00     15917\n",
      "\n",
      "    accuracy                           0.40     26340\n",
      "   macro avg       0.20      0.50      0.28     26340\n",
      "weighted avg       0.16      0.40      0.22     26340\n",
      "\n",
      "client No 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58      7394\n",
      "           1       0.00      0.00      0.00     10705\n",
      "\n",
      "    accuracy                           0.41     18099\n",
      "   macro avg       0.20      0.50      0.29     18099\n",
      "weighted avg       0.17      0.41      0.24     18099\n",
      "\n",
      "client No 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61      4234\n",
      "           1       0.00      0.00      0.00      5366\n",
      "\n",
      "    accuracy                           0.44      9600\n",
      "   macro avg       0.22      0.50      0.31      9600\n",
      "weighted avg       0.19      0.44      0.27      9600\n",
      "\n",
      "client No 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63      7081\n",
      "           1       0.00      0.00      0.00      8207\n",
      "\n",
      "    accuracy                           0.46     15288\n",
      "   macro avg       0.23      0.50      0.32     15288\n",
      "weighted avg       0.21      0.46      0.29     15288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#from audioop import mul\n",
    "#from multiprocessing.context import assert_spawning\n",
    "import os\n",
    "#from statistics import mode\n",
    "import timeit\n",
    "#from bitarray import test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sympy import N\n",
    "\n",
    "\n",
    "print(\"---Reading input file to pandas Dataframe---\")\n",
    "# dataset path\n",
    "path = 'data'\n",
    "file_name = 'churnsimulateddata.csv'\n",
    "file = os.path.join(path, file_name)\n",
    "print(file)\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f'Shape of original data: {df.shape}')\n",
    "\n",
    "print(\"---Select features---\")\n",
    "feature_names = ['Age','Tenure','PSYTE_Segment','Total_score','Trnx_count','num_products', 'Churn_risk']\n",
    "#feature_names = ['Age','PSYTE_Segment','Total_score','Churn_risk']\n",
    "#feature_names = ['PSYTE_Segment','Total_score','Churn_risk']\n",
    "\n",
    "selected_df = df[feature_names]\n",
    "\n",
    "selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'  \n",
    "\n",
    "selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
    "\n",
    "print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "selected_df = selected_df.dropna()\n",
    "#selected_df = selected_df.drop(selected_df[(selected_df.Churn_risk != 0) or (selected_df.Churn_risk != 1) (selected_df.Churn_risk != 2)].index)\n",
    "#print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "\n",
    "print('---Simulating clients based on geographical locations of the banks---') \n",
    "geo_split = 'T'\n",
    "if geo_split:\n",
    "    selected_df_v2 = selected_df.sample(frac=1)\n",
    "    clients_data = []\n",
    "    for i in range(0, 60, 10):\n",
    "        clients_data.append(selected_df_v2[(selected_df_v2.PSYTE_Segment >= i) & (selected_df_v2.PSYTE_Segment < i+10)]) \n",
    "    \n",
    "else:\n",
    "    n_clients = 10\n",
    "    clients_data = np.array_split(selected_df.sample(frac=1), n_clients)\n",
    "    \n",
    "print(f'Number of {np.size(clients_data)} clients. ')\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i, client_data in enumerate(clients_data):\n",
    "    X = client_data.drop(columns=['Churn_risk','PSYTE_Segment'])\n",
    "    print(X.columns)\n",
    "    y = client_data['Churn_risk']\n",
    "    \n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42) \n",
    "    print(np.shape(_X_train))\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "    #_X_train, _y_train = SMOTE().fit_resample(_X_train, _y_train)\n",
    "    #_X_train, _y_train = ADASYN().fit_resample(_X_train, _y_train)\n",
    "\n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "\n",
    "\n",
    "class LR_ScikitModel():\n",
    "    def __init__(self):\n",
    "        self.name = 'LR'\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        clf = LogisticRegression(multi_class='auto', max_iter=1000, n_jobs=-1)\n",
    "        starttime = timeit.default_timer()\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        model_params = clf.get_params() \n",
    "        training_time = timeit.default_timer() - starttime\n",
    "        print(\"The training time is :\", training_time)\n",
    "        #starttime = timeit.default_timer()\n",
    "        y_pred=clf.predict(X_test)\n",
    "        #precison = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        #print('Precison: ', precison)\n",
    "        #recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        #print('Recall: ', recall)\n",
    "        #f1 = metrics.f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        #print('F1: ', f1)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        #print('Intercept')\n",
    "        #print(clf.intercept_)\n",
    "        #print('Coefficients')\n",
    "        #print(clf.coef_)\n",
    "        \n",
    "        #testing_time = timeit.default_timer() - starttime\n",
    "        #print(\"The testing time is :\", testing_time)\n",
    "        return clf.intercept_, clf.coef_, accuracy\n",
    "\n",
    "\n",
    "print('---Training local models at local clients---')\n",
    "#Training Local model\n",
    "intercept_l = []\n",
    "coef_l = []\n",
    "accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "    intercept, coef, accuracy =  model.fit(X_train[i], X_test[i], y_train[i], y_test[i])\n",
    "    intercept_l.append(intercept)\n",
    "    coef_l.append(coef)\n",
    "    accuracy_l.append(accuracy)\n",
    "#print(intercept_l)\n",
    "#print(coef_l)\n",
    "#print(accuracy_l)\n",
    "\n",
    "\n",
    "print('---Aggregating at the aggregation server---')\n",
    "#averaged the local weights\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Constructing model---')\n",
    "#averaged the local weights\n",
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "print(global_intercept)\n",
    "print(global_coef)   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Testing on local clients---')\n",
    "#\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81cf84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ce4c055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.02300370e-01,  2.79518880e-01,  9.59302175e-01,\n",
       "          1.81650129e-03,  2.87066376e+00]]),\n",
       " array([-16.99110949]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(global_coef), np.array(global_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241083a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
