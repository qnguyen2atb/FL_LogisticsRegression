{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8390c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reading input file to pandas Dataframe---\n",
      "data/churnsimulateddata.csv\n",
      "Shape of original data: (706693, 19)\n",
      "---Select features---\n",
      "[1 0]\n",
      "---Simulating clients based on geographical locations of the banks---\n",
      "Number of 6 clients. \n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(127535, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_41404/1301323787.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:8870: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_41404/1301323787.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127535, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(160520, 5)\n",
      "(160520, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(105359, 5)\n",
      "(105359, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(72392, 5)\n",
      "(72392, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(38397, 5)\n",
      "(38397, 5)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products'], dtype='object')\n",
      "(61148, 5)\n",
      "(61148, 5)\n",
      "---Training local models at local clients---\n",
      "client No 0\n",
      "The training time is : 1.2816628750000518\n",
      "Accuracy:  0.8334274244134989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79     12555\n",
      "           1       0.86      0.86      0.86     19329\n",
      "\n",
      "    accuracy                           0.83     31884\n",
      "   macro avg       0.83      0.83      0.83     31884\n",
      "weighted avg       0.83      0.83      0.83     31884\n",
      "\n",
      "client No 1\n",
      "The training time is : 0.8641456250000488\n",
      "Accuracy:  0.8316264234631582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80     16532\n",
      "           1       0.86      0.85      0.86     23599\n",
      "\n",
      "    accuracy                           0.83     40131\n",
      "   macro avg       0.83      0.83      0.83     40131\n",
      "weighted avg       0.83      0.83      0.83     40131\n",
      "\n",
      "client No 2\n",
      "The training time is : 0.6248426660000064\n",
      "Accuracy:  0.8223614274867123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78     10557\n",
      "           1       0.85      0.85      0.85     15783\n",
      "\n",
      "    accuracy                           0.82     26340\n",
      "   macro avg       0.81      0.82      0.82     26340\n",
      "weighted avg       0.82      0.82      0.82     26340\n",
      "\n",
      "client No 3\n",
      "The training time is : 0.5281299170000011\n",
      "Accuracy:  0.8198795513564285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      7444\n",
      "           1       0.85      0.85      0.85     10655\n",
      "\n",
      "    accuracy                           0.82     18099\n",
      "   macro avg       0.81      0.81      0.81     18099\n",
      "weighted avg       0.82      0.82      0.82     18099\n",
      "\n",
      "client No 4\n",
      "The training time is : 0.6662870409999755\n",
      "Accuracy:  0.8195833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4236\n",
      "           1       0.85      0.83      0.84      5364\n",
      "\n",
      "    accuracy                           0.82      9600\n",
      "   macro avg       0.82      0.82      0.82      9600\n",
      "weighted avg       0.82      0.82      0.82      9600\n",
      "\n",
      "client No 5\n",
      "The training time is : 0.5292689170000244\n",
      "Accuracy:  0.8096546310832025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      7152\n",
      "           1       0.84      0.80      0.82      8136\n",
      "\n",
      "    accuracy                           0.81     15288\n",
      "   macro avg       0.81      0.81      0.81     15288\n",
      "weighted avg       0.81      0.81      0.81     15288\n",
      "\n",
      "---Aggregating at the aggregation server---\n",
      "---Constructing model---\n",
      "[-17.04847218]\n",
      "[[-1.00538977e-01  2.79191745e-01  9.59428405e-01  1.74130413e-03\n",
      "   2.87031140e+00]]\n",
      "---Testing on local clients---\n",
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.57     12555\n",
      "           1       0.00      0.00      0.00     19329\n",
      "\n",
      "    accuracy                           0.39     31884\n",
      "   macro avg       0.20      0.50      0.28     31884\n",
      "weighted avg       0.16      0.39      0.22     31884\n",
      "\n",
      "client No 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58     16532\n",
      "           1       0.00      0.00      0.00     23599\n",
      "\n",
      "    accuracy                           0.41     40131\n",
      "   macro avg       0.21      0.50      0.29     40131\n",
      "weighted avg       0.17      0.41      0.24     40131\n",
      "\n",
      "client No 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57     10557\n",
      "           1       0.00      0.00      0.00     15783\n",
      "\n",
      "    accuracy                           0.40     26340\n",
      "   macro avg       0.20      0.50      0.29     26340\n",
      "weighted avg       0.16      0.40      0.23     26340\n",
      "\n",
      "client No 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58      7444\n",
      "           1       0.00      0.00      0.00     10655\n",
      "\n",
      "    accuracy                           0.41     18099\n",
      "   macro avg       0.21      0.50      0.29     18099\n",
      "weighted avg       0.17      0.41      0.24     18099\n",
      "\n",
      "client No 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61      4236\n",
      "           1       0.00      0.00      0.00      5364\n",
      "\n",
      "    accuracy                           0.44      9600\n",
      "   macro avg       0.22      0.50      0.31      9600\n",
      "weighted avg       0.19      0.44      0.27      9600\n",
      "\n",
      "client No 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64      7152\n",
      "           1       0.00      0.00      0.00      8136\n",
      "\n",
      "    accuracy                           0.47     15288\n",
      "   macro avg       0.23      0.50      0.32     15288\n",
      "weighted avg       0.22      0.47      0.30     15288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#from audioop import mul\n",
    "#from multiprocessing.context import assert_spawning\n",
    "import os\n",
    "#from statistics import mode\n",
    "import timeit\n",
    "#from bitarray import test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sympy import N\n",
    "\n",
    "\n",
    "print(\"---Reading input file to pandas Dataframe---\")\n",
    "# dataset path\n",
    "path = 'data'\n",
    "file_name = 'churnsimulateddata.csv'\n",
    "file = os.path.join(path, file_name)\n",
    "print(file)\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f'Shape of original data: {df.shape}')\n",
    "\n",
    "print(\"---Select features---\")\n",
    "feature_names = ['Age','Tenure','PSYTE_Segment','Total_score','Trnx_count','num_products', 'Churn_risk']\n",
    "#feature_names = ['Age','PSYTE_Segment','Total_score','Churn_risk']\n",
    "#feature_names = ['PSYTE_Segment','Total_score','Churn_risk']\n",
    "\n",
    "selected_df = df[feature_names]\n",
    "\n",
    "selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'  \n",
    "\n",
    "selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
    "\n",
    "print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "selected_df = selected_df.dropna()\n",
    "#selected_df = selected_df.drop(selected_df[(selected_df.Churn_risk != 0) or (selected_df.Churn_risk != 1) (selected_df.Churn_risk != 2)].index)\n",
    "#print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "\n",
    "print('---Simulating clients based on geographical locations of the banks---') \n",
    "geo_split = 'T'\n",
    "if geo_split:\n",
    "    selected_df_v2 = selected_df.sample(frac=1)\n",
    "    clients_data = []\n",
    "    for i in range(0, 60, 10):\n",
    "        clients_data.append(selected_df_v2[(selected_df_v2.PSYTE_Segment >= i) & (selected_df_v2.PSYTE_Segment < i+10)]) \n",
    "    \n",
    "else:\n",
    "    n_clients = 10\n",
    "    clients_data = np.array_split(selected_df.sample(frac=1), n_clients)\n",
    "    \n",
    "print(f'Number of {np.size(clients_data)} clients. ')\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i, client_data in enumerate(clients_data):\n",
    "    X = client_data.drop(columns=['Churn_risk','PSYTE_Segment'])\n",
    "    print(X.columns)\n",
    "    y = client_data['Churn_risk']\n",
    "    \n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42) \n",
    "    print(np.shape(_X_train))\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "    #_X_train, _y_train = SMOTE().fit_resample(_X_train, _y_train)\n",
    "    #_X_train, _y_train = ADASYN().fit_resample(_X_train, _y_train)\n",
    "\n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "\n",
    "\n",
    "class LR_ScikitModel():\n",
    "    def __init__(self):\n",
    "        self.name = 'LR'\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        clf = LogisticRegression(multi_class='auto', max_iter=1000, n_jobs=-1)\n",
    "        starttime = timeit.default_timer()\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        model_params = clf.get_params() \n",
    "        training_time = timeit.default_timer() - starttime\n",
    "        print(\"The training time is :\", training_time)\n",
    "        #starttime = timeit.default_timer()\n",
    "        y_pred=clf.predict(X_test)\n",
    "        #precison = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        #print('Precison: ', precison)\n",
    "        #recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        #print('Recall: ', recall)\n",
    "        #f1 = metrics.f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        #print('F1: ', f1)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        #print('Intercept')\n",
    "        #print(clf.intercept_)\n",
    "        #print('Coefficients')\n",
    "        #print(clf.coef_)\n",
    "        \n",
    "        #testing_time = timeit.default_timer() - starttime\n",
    "        #print(\"The testing time is :\", testing_time)\n",
    "        return clf.intercept_, clf.coef_, accuracy\n",
    "\n",
    "\n",
    "print('---Training local models at local clients---')\n",
    "#Training Local model\n",
    "intercept_l = []\n",
    "coef_l = []\n",
    "accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "    intercept, coef, accuracy =  model.fit(X_train[i], X_test[i], y_train[i], y_test[i])\n",
    "    intercept_l.append(intercept)\n",
    "    coef_l.append(coef)\n",
    "    accuracy_l.append(accuracy)\n",
    "#print(intercept_l)\n",
    "#print(coef_l)\n",
    "#print(accuracy_l)\n",
    "\n",
    "\n",
    "print('---Aggregating at the aggregation server---')\n",
    "#averaged the local weights\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Constructing model---')\n",
    "#averaged the local weights\n",
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "print(global_intercept)\n",
    "print(global_coef)   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Testing on local clients---')\n",
    "#\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1017961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599608a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.02300370e-01,  2.79518880e-01,  9.59302175e-01,\n",
       "          1.81650129e-03,  2.87066376e+00]]),\n",
       " array([-16.99110949]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(global_coef), np.array(global_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c9575b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "Global model Accuracy:  38.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56     12416\n",
      "           1       0.00      0.00      0.00     19468\n",
      "\n",
      "    accuracy                           0.39     31884\n",
      "   macro avg       0.19      0.50      0.28     31884\n",
      "weighted avg       0.15      0.39      0.22     31884\n",
      "\n",
      "client No 1\n",
      "Global model Accuracy:  41.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59     16660\n",
      "           1       0.00      0.00      0.00     23471\n",
      "\n",
      "    accuracy                           0.42     40131\n",
      "   macro avg       0.21      0.50      0.29     40131\n",
      "weighted avg       0.17      0.42      0.24     40131\n",
      "\n",
      "client No 2\n",
      "Global model Accuracy:  39.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57     10423\n",
      "           1       0.00      0.00      0.00     15917\n",
      "\n",
      "    accuracy                           0.40     26340\n",
      "   macro avg       0.20      0.50      0.28     26340\n",
      "weighted avg       0.16      0.40      0.22     26340\n",
      "\n",
      "client No 3\n",
      "Global model Accuracy:  40.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58      7394\n",
      "           1       0.00      0.00      0.00     10705\n",
      "\n",
      "    accuracy                           0.41     18099\n",
      "   macro avg       0.20      0.50      0.29     18099\n",
      "weighted avg       0.17      0.41      0.24     18099\n",
      "\n",
      "client No 4\n",
      "Global model Accuracy:  44.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61      4234\n",
      "           1       0.00      0.00      0.00      5366\n",
      "\n",
      "    accuracy                           0.44      9600\n",
      "   macro avg       0.22      0.50      0.31      9600\n",
      "weighted avg       0.19      0.44      0.27      9600\n",
      "\n",
      "client No 5\n",
      "Global model Accuracy:  46.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63      7081\n",
      "           1       0.00      0.00      0.00      8207\n",
      "\n",
      "    accuracy                           0.46     15288\n",
      "   macro avg       0.23      0.50      0.32     15288\n",
      "weighted avg       0.21      0.46      0.29     15288\n",
      "\n",
      "[0.8356228829506963, 0.8313024843637089, 0.8246013667425968, 0.8189955246146196, 0.8189583333333333, 0.815018315018315] 0.8240831511705449\n",
      "[38.94, 41.51, 39.57, 40.85, 44.1, 46.32] 41.88166666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "gl_m_accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    gl_m_accuracy = round(accuracy_score(y_test[i], label)*100,2)\n",
    "    print('Global model Accuracy: ', gl_m_accuracy)\n",
    "    gl_m_accuracy_l.append(gl_m_accuracy)\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "    \n",
    "    \n",
    "print(accuracy_l, np.mean(accuracy_l))\n",
    "print(gl_m_accuracy_l, np.mean(gl_m_accuracy_l))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.loc[df.Churn_risk[df.Churn_risk == 'Medium'],df.Churn_risk] =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8185c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04081940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ufunc:\n",
      "\n",
      "multiply = <ufunc 'multiply'>\n",
      "    multiply(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n",
      "    \n",
      "    Multiply arguments element-wise.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x1, x2 : array_like\n",
      "        Input arrays to be multiplied.\n",
      "        If ``x1.shape != x2.shape``, they must be broadcastable to a common\n",
      "        shape (which becomes the shape of the output).\n",
      "    out : ndarray, None, or tuple of ndarray and None, optional\n",
      "        A location into which the result is stored. If provided, it must have\n",
      "        a shape that the inputs broadcast to. If not provided or None,\n",
      "        a freshly-allocated array is returned. A tuple (possible only as a\n",
      "        keyword argument) must have length equal to the number of outputs.\n",
      "    where : array_like, optional\n",
      "        This condition is broadcast over the input. At locations where the\n",
      "        condition is True, the `out` array will be set to the ufunc result.\n",
      "        Elsewhere, the `out` array will retain its original value.\n",
      "        Note that if an uninitialized `out` array is created via the default\n",
      "        ``out=None``, locations within it where the condition is False will\n",
      "        remain uninitialized.\n",
      "    **kwargs\n",
      "        For other keyword-only arguments, see the\n",
      "        :ref:`ufunc docs <ufuncs.kwargs>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    y : ndarray\n",
      "        The product of `x1` and `x2`, element-wise.\n",
      "        This is a scalar if both `x1` and `x2` are scalars.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Equivalent to `x1` * `x2` in terms of array broadcasting.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.multiply(2.0, 4.0)\n",
      "    8.0\n",
      "    \n",
      "    >>> x1 = np.arange(9.0).reshape((3, 3))\n",
      "    >>> x2 = np.arange(3.0)\n",
      "    >>> np.multiply(x1, x2)\n",
      "    array([[  0.,   1.,   4.],\n",
      "           [  0.,   4.,  10.],\n",
      "           [  0.,   7.,  16.]])\n",
      "    \n",
      "    The ``*`` operator can be used as a shorthand for ``np.multiply`` on\n",
      "    ndarrays.\n",
      "    \n",
      "    >>> x1 = np.arange(9.0).reshape((3, 3))\n",
      "    >>> x2 = np.arange(3.0)\n",
      "    >>> x1 * x2\n",
      "    array([[  0.,   1.,   4.],\n",
      "           [  0.,   4.,  10.],\n",
      "           [  0.,   7.,  16.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "help(\n",
    "    np.multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f9346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reading input file to pandas Dataframe---\n",
      "data/churnsimulateddata.csv\n",
      "Shape of original data: (706693, 19)\n",
      "---Select features---\n",
      "[1 2 0]\n",
      "---Simulating clients based on geographical locations of the banks---\n",
      "Number of 6 clients. \n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 0 2]\n",
      "(127535, 6)\n",
      "(127535, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[0 1 2]\n",
      "(160520, 6)\n",
      "(160520, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 2 0]\n",
      "(105359, 6)\n",
      "(105359, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[0 1 2]\n",
      "(72392, 6)\n",
      "(72392, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 2 0]\n",
      "(38397, 6)\n",
      "(38397, 6)\n",
      "Index(['Age', 'Tenure', 'Total_score', 'Trnx_count', 'num_products', 'A'], dtype='object')\n",
      "[1 0 2]\n",
      "(61148, 6)\n",
      "(61148, 6)\n",
      "---Training local models at local clients---\n",
      "client No 0\n",
      "[1 0 2] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "68903    29      14    32.000000         177             3   928.000000\n",
      "8056     58      22    17.166667         210             6   995.666667\n",
      "281076   74      16    14.000000          40             5  1036.000000\n",
      "543145   71      30    27.833333         108             8  1976.166667\n",
      "570772   31      21    14.166667          56             4   439.166667\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "137942   45      18    16.500000          67             1   742.500000\n",
      "381836   39       3    20.166667          75             2   786.500000\n",
      "385952   37       9    26.833333         539             2   992.833333\n",
      "52604    83      31    23.166667           6             2  1922.833333\n",
      "295452   35      17     0.000000           2             1     0.000000\n",
      "\n",
      "[127535 rows x 6 columns]\n",
      "68903     1\n",
      "8056      1\n",
      "281076    1\n",
      "543145    1\n",
      "570772    1\n",
      "         ..\n",
      "137942    1\n",
      "381836    1\n",
      "385952    1\n",
      "52604     1\n",
      "295452    0\n",
      "Name: Churn_risk, Length: 127535, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 1.4623351249992993\n",
      "Accuracy:  70.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.10      0.18      4676\n",
      "           1       0.81      0.93      0.86     19362\n",
      "           2       0.45      0.53      0.49      7846\n",
      "\n",
      "    accuracy                           0.71     31884\n",
      "   macro avg       0.70      0.52      0.51     31884\n",
      "weighted avg       0.72      0.71      0.67     31884\n",
      "\n",
      "client No 1\n",
      "[1 2 0] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "534294   55      24    33.666667           4             2  1851.666667\n",
      "514073   39       6    22.166667         117             1   864.500000\n",
      "568516   58       2     4.333333         183             1   251.333333\n",
      "340513   71       0     7.666667           3             1   544.333333\n",
      "323787   51       1     1.333333           7             2    68.000000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "579729   46       3     6.000000         679             1   276.000000\n",
      "35782    72      18    19.500000          30             1  1404.000000\n",
      "433618   74      19    45.333333         292             7  3354.666667\n",
      "97399    68      40    34.833333          21             1  2368.666667\n",
      "206611   29      18    36.500000         133             2  1058.500000\n",
      "\n",
      "[160520 rows x 6 columns]\n",
      "534294    1\n",
      "514073    1\n",
      "568516    2\n",
      "340513    0\n",
      "323787    0\n",
      "         ..\n",
      "579729    1\n",
      "35782     1\n",
      "433618    1\n",
      "97399     1\n",
      "206611    1\n",
      "Name: Churn_risk, Length: 160520, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.8829113749998214\n",
      "Accuracy:  66.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5667\n",
      "           1       0.74      0.94      0.83     23537\n",
      "           2       0.45      0.41      0.43     10927\n",
      "\n",
      "    accuracy                           0.67     40131\n",
      "   macro avg       0.40      0.45      0.42     40131\n",
      "weighted avg       0.56      0.67      0.60     40131\n",
      "\n",
      "client No 2\n",
      "[1 2 0] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "74245    46      24    40.666667          55             2  1870.666667\n",
      "542116   56       1    36.666667           4             2  2053.333333\n",
      "619110   59      33    13.833333         626             2   816.166667\n",
      "213302   22       1     0.000000         195             2     0.000000\n",
      "201687   49       6    30.833333          28             2  1510.833333\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "31885    20       3    21.833333          65             1   436.666667\n",
      "209571   38       4     8.000000          62             1   304.000000\n",
      "7741     58       3    20.833333          66             3  1208.333333\n",
      "541085   32      22    47.500000          65             1  1520.000000\n",
      "26618    46       3    25.166667         124             2  1157.666667\n",
      "\n",
      "[105359 rows x 6 columns]\n",
      "74245     1\n",
      "542116    1\n",
      "619110    1\n",
      "213302    2\n",
      "201687    1\n",
      "         ..\n",
      "31885     1\n",
      "209571    2\n",
      "7741      1\n",
      "541085    1\n",
      "26618     1\n",
      "Name: Churn_risk, Length: 105359, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.7275706669997817\n",
      "Accuracy:  67.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3534\n",
      "           1       0.74      0.95      0.83     15827\n",
      "           2       0.44      0.37      0.40      6979\n",
      "\n",
      "    accuracy                           0.67     26340\n",
      "   macro avg       0.39      0.44      0.41     26340\n",
      "weighted avg       0.56      0.67      0.61     26340\n",
      "\n",
      "client No 3\n",
      "[1 0 2] [0 1 2]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "105331   54      39    55.166667          50             4  2979.000000\n",
      "283655   50       0    12.666667          17             2   633.333333\n",
      "219105   68       9     8.166667          27             1   555.333333\n",
      "276929   50      15    13.166667           4             1   658.333333\n",
      "203305   65      20    34.000000          11             4  2210.000000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "566444   27       3     9.000000          19             1   243.000000\n",
      "569270   73      39     8.500000        1294             4   620.500000\n",
      "488091   27      20    22.666667         110             2   612.000000\n",
      "598488   56       5    14.166667         443             2   793.333333\n",
      "340559   60      27    13.666667           1             1   820.000000\n",
      "\n",
      "[72392 rows x 6 columns]\n",
      "105331    1\n",
      "283655    1\n",
      "219105    1\n",
      "276929    1\n",
      "203305    1\n",
      "         ..\n",
      "566444    1\n",
      "569270    1\n",
      "488091    1\n",
      "598488    2\n",
      "340559    0\n",
      "Name: Churn_risk, Length: 72392, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.619735166999817\n",
      "Accuracy:  66.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2436\n",
      "           1       0.74      0.94      0.83     10768\n",
      "           2       0.44      0.39      0.41      4895\n",
      "\n",
      "    accuracy                           0.67     18099\n",
      "   macro avg       0.39      0.44      0.41     18099\n",
      "weighted avg       0.56      0.67      0.60     18099\n",
      "\n",
      "client No 4\n",
      "[2 0 1] [2 1 0]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "222826   40       6     1.833333          57             2    73.333333\n",
      "296873   65      21     1.500000          13             2    97.500000\n",
      "180392   24      11    32.500000          84             2   780.000000\n",
      "30011    50      31    25.166667         121             5  1258.333333\n",
      "704439   39       7     7.166667          42             1   279.500000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "379378   66       2    14.833333           3             2   979.000000\n",
      "684081   68      20     0.000000         130             1     0.000000\n",
      "693571   45       3     7.000000          37             1   315.000000\n",
      "346174   29       1     0.000000           8             1     0.000000\n",
      "688494   47      17    10.500000           3             2   493.500000\n",
      "\n",
      "[38397 rows x 6 columns]\n",
      "222826    2\n",
      "296873    0\n",
      "180392    1\n",
      "30011     1\n",
      "704439    0\n",
      "         ..\n",
      "379378    1\n",
      "684081    2\n",
      "693571    2\n",
      "346174    0\n",
      "688494    2\n",
      "Name: Churn_risk, Length: 38397, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.5119907500002228\n",
      "Accuracy:  63.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1537\n",
      "           1       0.70      0.94      0.80      5299\n",
      "           2       0.43      0.39      0.41      2764\n",
      "\n",
      "    accuracy                           0.63      9600\n",
      "   macro avg       0.38      0.44      0.41      9600\n",
      "weighted avg       0.51      0.63      0.56      9600\n",
      "\n",
      "client No 5\n",
      "[2 1 0] [1 0 2]\n",
      "        Age  Tenure  Total_score  Trnx_count  num_products            A\n",
      "577658   87      45    12.166667          12             2  1058.500000\n",
      "222903   27      23     7.666667         137             3   207.000000\n",
      "587310   38      13     1.500000         283             1    57.000000\n",
      "39158    35       2    22.833333         100             2   799.166667\n",
      "607866   50       0     0.500000         163             1    25.000000\n",
      "...     ...     ...          ...         ...           ...          ...\n",
      "219650   40       4     8.666667          87             2   346.666667\n",
      "252959   67      17     2.333333          60             2   156.333333\n",
      "74631    31      12    44.000000          50             5  1364.000000\n",
      "157239   31       2    18.833333          49             1   583.833333\n",
      "3496     55      21    19.000000          40             3  1045.000000\n",
      "\n",
      "[61148 rows x 6 columns]\n",
      "577658    2\n",
      "222903    1\n",
      "587310    1\n",
      "39158     1\n",
      "607866    2\n",
      "         ..\n",
      "219650    1\n",
      "252959    1\n",
      "74631     1\n",
      "157239    2\n",
      "3496      1\n",
      "Name: Churn_risk, Length: 61148, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time is : 0.724646916999518\n",
      "Accuracy:  64.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.26      0.39      2729\n",
      "           1       0.69      0.93      0.79      8061\n",
      "           2       0.48      0.38      0.42      4498\n",
      "\n",
      "    accuracy                           0.65     15288\n",
      "   macro avg       0.65      0.52      0.54     15288\n",
      "weighted avg       0.65      0.65      0.61     15288\n",
      "\n",
      "[array([ 0.00022204, -0.00036875,  0.00014671]), array([ 6.34492089e-05, -1.27139667e-04,  6.36904577e-05]), array([ 4.94228878e-05, -1.07728907e-04,  5.83060191e-05]), array([ 7.96757407e-05, -1.59013683e-04,  7.93379421e-05]), array([ 7.03996921e-05, -1.39526366e-04,  6.91266736e-05]), array([ 9.67864203e-05, -1.69083973e-04,  7.22975531e-05])]\n",
      "[array([[ 1.23649509e-02,  7.77695958e-04, -8.57747894e-04,\n",
      "        -4.74196027e-03,  8.99774481e-05, -1.86673072e-03],\n",
      "       [-2.28737437e-02, -1.43591828e-03,  2.50138534e-03,\n",
      "         2.81603643e-03, -1.04581328e-05,  2.38883231e-03],\n",
      "       [ 1.05087928e-02,  6.58222325e-04, -1.64363745e-03,\n",
      "         1.92592384e-03, -7.95193153e-05, -5.22101590e-04]]), array([[ 3.68308116e-03,  3.14160873e-04, -3.14655414e-04,\n",
      "        -1.46445961e-03,  2.92704641e-05, -2.54693037e-03],\n",
      "       [-8.10568356e-03, -6.84264952e-04,  8.93590257e-04,\n",
      "         6.09709634e-04, -4.33342786e-07,  2.17761518e-03],\n",
      "       [ 4.42260240e-03,  3.70104079e-04, -5.78934843e-04,\n",
      "         8.54749980e-04, -2.88371213e-05,  3.69315185e-04]]), array([[ 3.21000556e-03,  2.55406800e-04, -3.25028071e-04,\n",
      "        -2.05579641e-03,  1.29676693e-05, -2.16453763e-03],\n",
      "       [-7.55163876e-03, -6.47636287e-04,  9.45335730e-04,\n",
      "         1.05043742e-03,  1.58993578e-05,  1.94118626e-03],\n",
      "       [ 4.34163320e-03,  3.92229487e-04, -6.20307659e-04,\n",
      "         1.00535899e-03, -2.88670271e-05,  2.23351368e-04]]), array([[ 5.11476240e-03,  3.54937306e-04, -4.90847221e-04,\n",
      "        -1.89150935e-03,  3.05294687e-05, -2.50379541e-03],\n",
      "       [-1.12130227e-02, -8.54662349e-04,  1.37746273e-03,\n",
      "         1.04471579e-03,  9.35880649e-06,  2.32327142e-03],\n",
      "       [ 6.09826026e-03,  4.99725043e-04, -8.86615505e-04,\n",
      "         8.46793558e-04, -3.98882752e-05,  1.80523992e-04]]), array([[ 4.11620654e-03,  2.60212670e-04, -3.36434140e-04,\n",
      "        -7.00664146e-04,  3.51154450e-05, -2.65445971e-03],\n",
      "       [-8.97995937e-03, -5.41330939e-04,  9.56001948e-04,\n",
      "         2.05328227e-04,  5.09293911e-07,  2.36071958e-03],\n",
      "       [ 4.86375283e-03,  2.81118269e-04, -6.19567808e-04,\n",
      "         4.95335919e-04, -3.56247389e-05,  2.93740124e-04]]), array([[ 5.44104397e-03,  4.15874492e-04, -4.57262634e-04,\n",
      "         3.54366594e-05,  5.05411200e-05, -2.90858011e-03],\n",
      "       [-1.07400622e-02, -8.70150511e-04,  1.33303214e-03,\n",
      "        -9.26670187e-05,  1.89785648e-06,  2.51427736e-03],\n",
      "       [ 5.29901828e-03,  4.54276019e-04, -8.75769503e-04,\n",
      "         5.72303593e-05, -5.24389764e-05,  3.94302748e-04]])]\n",
      "[70.64, 66.63, 67.12, 66.66, 63.12, 64.7]\n",
      "---Aggregating at the aggregation server---\n",
      "---Constructing model---\n",
      "---Testing on local clients---\n",
      "---Testing global model on local testing data---\n",
      "client No 0\n",
      "Global model Accuracy:  67.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4676\n",
      "           1       0.77      0.95      0.85     19362\n",
      "           2       0.41      0.41      0.41      7846\n",
      "\n",
      "    accuracy                           0.68     31884\n",
      "   macro avg       0.39      0.45      0.42     31884\n",
      "weighted avg       0.57      0.68      0.62     31884\n",
      "\n",
      "client No 1\n",
      "Global model Accuracy:  67.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5667\n",
      "           1       0.76      0.94      0.84     23537\n",
      "           2       0.46      0.46      0.46     10927\n",
      "\n",
      "    accuracy                           0.68     40131\n",
      "   macro avg       0.41      0.47      0.43     40131\n",
      "weighted avg       0.57      0.68      0.62     40131\n",
      "\n",
      "client No 2\n",
      "Global model Accuracy:  68.08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3534\n",
      "           1       0.76      0.94      0.84     15827\n",
      "           2       0.45      0.44      0.45      6979\n",
      "\n",
      "    accuracy                           0.68     26340\n",
      "   macro avg       0.40      0.46      0.43     26340\n",
      "weighted avg       0.58      0.68      0.62     26340\n",
      "\n",
      "client No 3\n",
      "Global model Accuracy:  66.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2436\n",
      "           1       0.74      0.94      0.83     10768\n",
      "           2       0.44      0.41      0.42      4895\n",
      "\n",
      "    accuracy                           0.67     18099\n",
      "   macro avg       0.39      0.45      0.42     18099\n",
      "weighted avg       0.56      0.67      0.61     18099\n",
      "\n",
      "client No 4\n",
      "Global model Accuracy:  64.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1537\n",
      "           1       0.72      0.93      0.81      5299\n",
      "           2       0.45      0.44      0.44      2764\n",
      "\n",
      "    accuracy                           0.64      9600\n",
      "   macro avg       0.39      0.46      0.42      9600\n",
      "weighted avg       0.53      0.64      0.58      9600\n",
      "\n",
      "client No 5\n",
      "Global model Accuracy:  61.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2729\n",
      "           1       0.70      0.93      0.80      8061\n",
      "           2       0.43      0.43      0.43      4498\n",
      "\n",
      "    accuracy                           0.62     15288\n",
      "   macro avg       0.37      0.45      0.41     15288\n",
      "weighted avg       0.49      0.62      0.55     15288\n",
      "\n",
      "[70.64, 66.63, 67.12, 66.66, 63.12, 64.7] 66.47833333333332\n",
      "[67.88, 67.77, 68.08, 66.73, 64.15, 61.56] 66.02833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#from audioop import mul\n",
    "#from multiprocessing.context import assert_spawning\n",
    "import os\n",
    "#from statistics import mode\n",
    "import timeit\n",
    "#from bitarray import test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "#from sympy import N\n",
    "\n",
    "\n",
    "print(\"---Reading input file to pandas Dataframe---\")\n",
    "# dataset path\n",
    "path = 'data'\n",
    "file_name = 'churnsimulateddata.csv'\n",
    "file = os.path.join(path, file_name)\n",
    "print(file)\n",
    "# read data\n",
    "df = pd.read_csv(file)\n",
    "print(f'Shape of original data: {df.shape}')\n",
    "\n",
    "print(\"---Select features---\")\n",
    "feature_names = ['Age','Tenure','PSYTE_Segment','Total_score','Trnx_count','num_products', 'Churn_risk']\n",
    "#feature_names = ['Age','PSYTE_Segment','Total_score','Churn_risk']\n",
    "#feature_names = ['PSYTE_Segment','Total_score','Churn_risk']\n",
    "\n",
    "selected_df = df[feature_names].dropna()\n",
    "\n",
    "\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = 'High'  \n",
    "\n",
    "selected_df['Churn_risk'] = selected_df.Churn_risk.astype(\"category\").cat.codes\n",
    "selected_df['A'] = selected_df.Age * selected_df.Total_score\n",
    "#selected_df['B'] = selected_df.Churn_risk * selected_df.Total_score\n",
    "\n",
    "\n",
    "#print(selected_df['Churn_risk'][selected_df['Churn_risk_code'] == 0]) #HIGH\n",
    "#print(selected_df['Churn_risk'][selected_df['Churn_risk_code'] == 1]) #LOW\n",
    "#print(selected_df['Churn_risk'][selected_df['Churn_risk_code'] == 2]) #MED\n",
    "\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Medium'] = '1'\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'Low'] = '0'\n",
    "#selected_df['Churn_risk'][selected_df['Churn_risk'] == 'High'] = '2'\n",
    "\n",
    "\n",
    "print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "selected_df = selected_df.dropna()\n",
    "#selected_df = selected_df.drop(selected_df[(selected_df.Churn_risk != 0) or (selected_df.Churn_risk != 1) (selected_df.Churn_risk != 2)].index)\n",
    "#print(selected_df['Churn_risk'].unique())\n",
    "\n",
    "classes = np.unique(selected_df['Churn_risk'])\n",
    "class_labels = {c:i for i,c in enumerate(classes)}\n",
    "def one_hot(y):\n",
    "    return np.eye(len(classes))[np.vectorize(lambda c: class_labels[c])(y).reshape(-1)]\n",
    "\n",
    "print('---Simulating clients based on geographical locations of the banks---') \n",
    "geo_split = 'T'\n",
    "if geo_split:\n",
    "    selected_df_v2 = selected_df.sample(frac=1)\n",
    "    clients_data = []\n",
    "    for i in range(0, 60, 10):\n",
    "        y = selected_df_v2[(selected_df_v2.PSYTE_Segment >= i) & (selected_df_v2.PSYTE_Segment < i+10)]\n",
    "        clients_data.append(y) \n",
    "    \n",
    "else:\n",
    "    n_clients = 10\n",
    "    clients_data = np.array_split(selected_df.sample(frac=1), n_clients)\n",
    "    \n",
    "print(f'Number of {np.size(clients_data)} clients. ')\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i, client_data in enumerate(clients_data):\n",
    "    X = client_data.drop(columns=['Churn_risk','PSYTE_Segment'])\n",
    "    print(X.columns)\n",
    "    y = client_data['Churn_risk']\n",
    "    print(y.unique())\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42) \n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # downsample majority\n",
    "    # concatenate our training data back together\n",
    "    X = pd.concat([_X_train, _y_train], axis=1)\n",
    "    low = X[X.Churn_risk==1]\n",
    "    high = X[X.Churn_risk==0]\n",
    "    medium = X[X.Churn_risk==2]\n",
    "    \n",
    "    X.Churn_risk.value_counts()\n",
    "\n",
    "    low_downsampled = resample(low,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(medium), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "    # combine minority and downsampled majority\n",
    "    downsampled = pd.concat([low_downsampled, high, medium])\n",
    "\n",
    "    # checking counts\n",
    "    downsampled.Churn_risk.value_counts()\n",
    "\n",
    "    _X_train = downsampled.drop('Churn_risk', axis=1)\n",
    "    _y_train = downsampled.Churn_risk\n",
    "    '''\n",
    "\n",
    "    #oversamppling\n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "    #_X_train, _y_train = SMOTE().fit_resample(_X_train, _y_train)\n",
    "    #_X_train, _y_train = ADASYN().fit_resample(_X_train, _y_train)\n",
    "\n",
    "    \n",
    "    print(np.shape(_X_train))\n",
    "\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "\n",
    "\n",
    "class LR_ScikitModel():\n",
    "    def __init__(self):\n",
    "        self.name = 'LR'\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        clf = LogisticRegression(multi_class='multinomial', max_iter=10, n_jobs=-1)\n",
    "        #clf = LogisticRegression(multi_class='auto', max_iter=500, n_jobs=-1)\n",
    "        \n",
    "        starttime = timeit.default_timer()\n",
    "        #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "        print(X_train)\n",
    "        print(y_train)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        model_params = clf.get_params() \n",
    "        training_time = timeit.default_timer() - starttime\n",
    "        print(\"The training time is :\", training_time)\n",
    "        #starttime = timeit.default_timer()\n",
    "        y_pred=clf.predict(X_test)\n",
    "        #precison = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        #print('Precison: ', precison)\n",
    "        #recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        #print('Recall: ', recall)\n",
    "        #f1 = metrics.f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "        #print('F1: ', f1)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,2)\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        #print('Intercept')\n",
    "        #print(clf.intercept_)\n",
    "        #print('Coefficients')\n",
    "        #print(clf.coef_)\n",
    "        \n",
    "        #testing_time = timeit.default_timer() - starttime\n",
    "        #print(\"The testing time is :\", testing_time)\n",
    "        return clf.intercept_, clf.coef_, accuracy\n",
    "\n",
    "\n",
    "print('---Training local models at local clients---')\n",
    "#Training Local model\n",
    "intercept_l = []\n",
    "coef_l = []\n",
    "row_l = []\n",
    "accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "    print(y_train[i].unique(), y_test[i].unique())\n",
    "    intercept, coef, accuracy =  model.fit(X_train[i], X_test[i], y_train[i], y_test[i])\n",
    "    intercept_l.append(intercept)\n",
    "    coef_l.append(coef)\n",
    "    accuracy_l.append(accuracy)\n",
    "    row_l.append(np.size(accuracy))\n",
    "print(intercept_l)\n",
    "print(coef_l)\n",
    "print(accuracy_l)\n",
    "\n",
    "\n",
    "print('---Aggregating at the aggregation server---')\n",
    "#averaged the local weights\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "print('---Constructing model---')\n",
    "#averaged the local weights\n",
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "#print(np.shape(global_intercept))\n",
    "#print(np.shape(global_coef))   # axis1=3 becasue there is 3 classes\n",
    "#global_intercept = np.sum(intercept_l*row_l)/np.sum(row_l)\n",
    "#global_coef = np.sum(np.multiply(coef_l, row_l))/np.sum(row_l)\n",
    "#print(np.shape(global_intercept))\n",
    "#print(np.shape(global_coef))\n",
    "\n",
    "\n",
    "print('---Testing on local clients---')\n",
    "#\n",
    "#print(np.sum(intercept_l,axis=0))\n",
    "#print(np.sum(coef_l,axis=0))   # axis1=3 becasue there is 3 classes\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_LogisticFunction(X, W, b):\n",
    "    '''\n",
    "    Logistics Regression function\n",
    "    Input: \n",
    "        X: input data in form of a matrix with size (n_samples, n_features)\n",
    "        W: Weight or logistics coefficient matrix with size (n_classes, n_features)\n",
    "        b: bias or intercept vector with size (n_classes)  \n",
    "        ref: https://github.com/bamtak/machine-learning-implemetation-python/blob/master/Multi%20Class%20Logistic%20Regression.ipynb\n",
    "    '''\n",
    "\n",
    "    def softmax(z):\n",
    "        prob = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "        return prob\n",
    "            \n",
    "    def predict_(X, W, b):\n",
    "\n",
    "        assert np.shape(X)[1] == np.shape(W)[1]   \n",
    "        assert np.shape(W)[0] == np.shape(b)[0]   \n",
    "\n",
    "        pre_vals = np.dot(X, W.T) + b\n",
    "        return softmax(pre_vals)\n",
    "    \n",
    "    probability = predict_(X, W, b)\n",
    "    max_prob = np.amax(probability, axis=1, keepdims=True)\n",
    "    #print(np.shape(max_prob))\n",
    "    label = np.argmax(probability, axis=1)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "print('---Testing global model on local testing data---')\n",
    "gl_m_accuracy_l = []\n",
    "for i in range(np.size(clients_data)):\n",
    "    print(f'client No {i}')\n",
    "    model = LR_ScikitModel()\n",
    "\n",
    "    label =  multiclass_LogisticFunction(X_test[i], np.array(global_coef), np.array(global_intercept))\n",
    "    gl_m_accuracy = round(accuracy_score(y_test[i], label)*100,2)\n",
    "    print('Global model Accuracy: ', gl_m_accuracy)\n",
    "    gl_m_accuracy_l.append(gl_m_accuracy)\n",
    "    print(classification_report(y_test[i], label, zero_division=0))\n",
    "    \n",
    "    \n",
    "print(accuracy_l, np.mean(accuracy_l))\n",
    "print(gl_m_accuracy_l, np.mean(gl_m_accuracy_l))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8793b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "(6, 3, 6)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "global_intercept = np.sum(intercept_l,axis=0)\n",
    "global_coef = np.sum(coef_l,axis=0) \n",
    "print(np.shape(intercept_l))\n",
    "print(np.shape(coef_l))   # axis1=3 becasue there is 3 classes\n",
    "print(np.shape(row_l))\n",
    "#global_intercept = np.sum(intercept_l*row_l)/np.sum(row_l)\n",
    "#global_coef = np.sum(np.multiply(coef_l, row_l))/np.sum(row_l)\n",
    "#print(np.shape(global_intercept))\n",
    "#print(np.shape(global_coef))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147e272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "gl_m_accuracy = f1_score(y_test[i], label,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d23c77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.79530237, 0.42728984])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_m_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a863d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = [[0.71101752, 0.7836647 , 0.50746934], [0.71278725, 0.79218125, 0.517991  ], [0.69646681, 0.78045157, 0.50823673], [0.69844284, 0.77568922, 0.49197145], [0.68932331, 0.77653997, 0.4966818 ], [0.69084746, 0.77533719, 0.49375755]] \n",
    "b = [[0.7104107 , 0.78084087, 0.49949193], [0.7124484 , 0.7912401 , 0.51175971], [0.6972058 , 0.77861246, 0.50651141], [0.6998088 , 0.77641686, 0.49832999], [0.68797106, 0.77594184, 0.49982741], [0.69178547, 0.7714565 , 0.49356308]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7142dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71101752, 0.7836647, 0.50746934], [0.71278725, 0.79218125, 0.517991], [0.69646681, 0.78045157, 0.50823673], [0.69844284, 0.77568922, 0.49197145], [0.68932331, 0.77653997, 0.4966818], [0.69084746, 0.77533719, 0.49375755]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef8f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7104107, 0.78084087, 0.49949193], [0.7124484, 0.7912401, 0.51175971], [0.6972058, 0.77861246, 0.50651141], [0.6998088, 0.77641686, 0.49832999], [0.68797106, 0.77594184, 0.49982741], [0.69178547, 0.7714565, 0.49356308]]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5e714cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'High'), Text(1, 0, 'Low'), Text(2, 0, 'Medium')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "fig.suptitle('f1-score')\n",
    "data = [[0.71101752, 0.7836647 , 0.50746934], [0.71278725, 0.79218125, 0.517991  ], [0.69646681, 0.78045157, 0.50823673], [0.69844284, 0.77568922, 0.49197145], [0.68932331, 0.77653997, 0.4966818 ], [0.69084746, 0.77533719, 0.49375755]] \n",
    "data_b = [[0.7104107 , 0.78084087, 0.49949193], [0.7124484 , 0.7912401 , 0.51175971], [0.6972058 , 0.77861246, 0.50651141], [0.6998088 , 0.77641686, 0.49832999], [0.68797106, 0.77594184, 0.49982741], [0.69178547, 0.7714565 , 0.49356308]]\n",
    "\n",
    "X = np.arange(3)\n",
    "#fig = plt.figure()\n",
    "#ax1 = fig.add_axes([0,0,1,1])\n",
    "color_l = ['b','g', 'y','r','c', 'm', 'k', 'black','purple', 'pink', 'olive', 'gray', 'orange', 'lime']\n",
    "for i in range(np.shape(data)[0]):\n",
    "    ax1.bar(X + 0.1*i, data[i], color = color_l[i], width = 0.1)\n",
    "ax1.set_title('Local Model')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_xticks([0,1,2])\n",
    "#ax1.set_xticks(['High','Low','Medium'])\n",
    "ax1.set_xticklabels(['High','Low','Medium'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(np.shape(data)[0]):\n",
    "    ax2.bar(X + 0.1*i, data_b[i], color = color_l[i], width = 0.1)\n",
    "ax2.set_title('Global Model')\n",
    "ax1.set_xticklabels(['High','Low','Medium'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3db849eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_42308/1907439723.py:28: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_xticklabels(['High','Low','Medium'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4, 0.8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [[0.71858002, 0.78539607, 0.51764706], [0.70903522, 0.79434704, 0.51279562], [0.71717422, 0.78819733, 0.52413793], [0.68879128, 0.77404108, 0.48724781], [0.70168122, 0.77377145, 0.50980971], [0.70197244, 0.78187221, 0.51945289], [0.70777378, 0.77360033, 0.50754516], [0.70929998, 0.77409507, 0.50526316], [0.68939864, 0.76226158, 0.49964614], [0.68831169, 0.76148366, 0.49173445], [0.67838019, 0.76283252, 0.46663987], [0.70535349, 0.78248848, 0.49773756]]\n",
    "data_b = [[0.71805662, 0.78485075, 0.51299359], [0.70827981, 0.79468711, 0.50300587], [0.71390091, 0.78776713, 0.51228752], [0.6896106 , 0.77158672, 0.48856981], [0.70182343, 0.77485254, 0.51095323], [0.70440252, 0.78589055, 0.52266093], [0.70727065, 0.77257933, 0.51017812], [0.70912779, 0.77412281, 0.51109057], [0.69223631, 0.75843271, 0.4929078 ], [0.6903255 , 0.75666164, 0.50684237], [0.67907445, 0.76197719, 0.47414133], [0.70121457, 0.78236398, 0.49401198]]\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,5))\n",
    "fig.suptitle('f1-score')\n",
    "X = np.arange(3)\n",
    "#fig = plt.figure()\n",
    "#ax1 = fig.add_axes([0,0,1,1])\n",
    "color_l = ['b','g', 'y','r','c', 'm', 'k', 'black','purple', 'pink', 'olive', 'gray', 'orange', 'lime']\n",
    "for i in range(np.shape(data)[0]):\n",
    "    ax1.bar(X + 0.05*i, data[i], color = color_l[i], width = 0.05)\n",
    "ax1.set_title('Local Model')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_xticks([0.2,1.2,2.2])\n",
    "#ax1.set_xticks(['High','Low','Medium'])\n",
    "ax1.set_xticklabels(['High','Low','Medium'])\n",
    "#ax1.axhline(y=0.5, color='r', linestyle='-')\n",
    "ax1.set_ylim([0.4, 0.8])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(np.shape(data)[0]):\n",
    "    ax2.bar(X + 0.05*i, data_b[i], color = color_l[i], width = 0.05)\n",
    "ax2.set_title('Global Model')\n",
    "ax2.set_xticklabels(['High','Low','Medium'])\n",
    "#ax2.axhline(y=0.5, color='r', linestyle='-')\n",
    "ax2.set_xticks([0.2,1.2,2.2])\n",
    "ax2.set_ylim([0.4, 0.8])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46e91c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "data = [[0.71858002, 0.78539607, 0.51764706], [0.70903522, 0.79434704, 0.51279562], [0.71717422, 0.78819733, 0.52413793], [0.68879128, 0.77404108, 0.48724781], [0.70168122, 0.77377145, 0.50980971], [0.70197244, 0.78187221, 0.51945289], [0.70777378, 0.77360033, 0.50754516], [0.70929998, 0.77409507, 0.50526316], [0.68939864, 0.76226158, 0.49964614], [0.68831169, 0.76148366, 0.49173445], [0.67838019, 0.76283252, 0.46663987], [0.70535349, 0.78248848, 0.49773756]]\n",
    "data_b = [[0.71805662, 0.78485075, 0.51299359], [0.70827981, 0.79468711, 0.50300587], [0.71390091, 0.78776713, 0.51228752], [0.6896106 , 0.77158672, 0.48856981], [0.70182343, 0.77485254, 0.51095323], [0.70440252, 0.78589055, 0.52266093], [0.70727065, 0.77257933, 0.51017812], [0.70912779, 0.77412281, 0.51109057], [0.69223631, 0.75843271, 0.4929078 ], [0.6903255 , 0.75666164, 0.50684237], [0.67907445, 0.76197719, 0.47414133], [0.70121457, 0.78236398, 0.49401198]]\n",
    "\n",
    "\n",
    "\n",
    "k = 0\n",
    "for i in range(np.shape(data)[0]):\n",
    "    for j in range(np.shape(data_b)[1]):\n",
    "        diff =(data[i][j]-data_b[i][j])*100\n",
    "        if diff>0:\n",
    "            k = k+1\n",
    "print(k)\n",
    "        \n",
    "        \n",
    "19/36    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6ef2c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'matplotlib.colors' from '/opt/anaconda3/lib/python3.9/site-packages/matplotlib/colors.py'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b4080a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-0.03329060953930485\n",
      "1\n",
      "-0.3679728980786501\n",
      "2\n",
      "-0.4203542918450598\n",
      "3\n",
      "-0.4792542551338874\n",
      "4\n",
      "-0.618382278971652\n",
      "5\n",
      "-0.38783465994692845\n",
      "6\n",
      "-0.18364072901941864\n",
      "7\n",
      "-0.12419521680365753\n",
      "8\n",
      "-0.05544116310738367\n",
      "9\n",
      "0.0052214301713093825\n",
      "10\n",
      "0.22578315073373822\n",
      "11\n",
      "0.004919761556143598\n",
      "12\n",
      "0.21455035316780835\n",
      "13\n",
      "-0.17056401427770762\n",
      "14\n",
      "0.511246185079095\n",
      "15\n",
      "0.846309969093606\n",
      "16\n",
      "0.4068157657789562\n",
      "17\n",
      "0.3763421100233977\n",
      "18\n",
      "-0.40034323517674775\n",
      "19\n",
      "-0.32150178184552347\n"
     ]
    }
   ],
   "source": [
    "a = [0.6765301225454903, 0.6702671565450588, 0.6764931777943638, 0.6685905207298473, 0.6711576562164527, 0.6592708376515557, 0.6577360501934458, 0.656482168632823, 0.6707884595018007, 0.6706052415390984, 0.6583376210407832, 0.6519607133705146, 0.653086858937941, 0.6570538738263334, 0.6458673528116866, 0.646617347734729, 0.6475928993546793, 0.6502021042795388, 0.6564011177506406, 0.647701248870923]\n",
    "b = [0.6761972164500972, 0.6665874275642723, 0.6722896348759132, 0.6637979781785084, 0.6649738334267362, 0.6553924910520864, 0.6558996429032516, 0.6552402164647865, 0.6702340478707268, 0.6706574558408115, 0.6605954525481206, 0.6520099109860761, 0.6552323624696191, 0.6553482336835563, 0.6509798146624776, 0.6550804474256651, 0.6516610570124689, 0.6539655253797728, 0.6523976853988731, 0.6444862310524677]\n",
    "for i in range(np.size(a)):\n",
    "    print(i)\n",
    "    print((b[i]-a[i])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6ce35293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_42308/1437713800.py:30: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_xticklabels(['High','Low','Medium'])\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9837c8f070>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [[0.71858002, 0.78539607, 0.51764706], [0.70903522, 0.79434704, 0.51279562], [0.71717422, 0.78819733, 0.52413793], [0.68879128, 0.77404108, 0.48724781], [0.70168122, 0.77377145, 0.50980971], [0.70197244, 0.78187221, 0.51945289], [0.70777378, 0.77360033, 0.50754516], [0.70929998, 0.77409507, 0.50526316], [0.68939864, 0.76226158, 0.49964614], [0.68831169, 0.76148366, 0.49173445], [0.67838019, 0.76283252, 0.46663987], [0.70535349, 0.78248848, 0.49773756]]\n",
    "data_b = [[0.71805662, 0.78485075, 0.51299359], [0.70827981, 0.79468711, 0.50300587], [0.71390091, 0.78776713, 0.51228752], [0.6896106 , 0.77158672, 0.48856981], [0.70182343, 0.77485254, 0.51095323], [0.70440252, 0.78589055, 0.52266093], [0.70727065, 0.77257933, 0.51017812], [0.70912779, 0.77412281, 0.51109057], [0.69223631, 0.75843271, 0.4929078 ], [0.6903255 , 0.75666164, 0.50684237], [0.67907445, 0.76197719, 0.47414133], [0.70121457, 0.78236398, 0.49401198]]\n",
    "\n",
    "class_0 = [0.71858002, ]\n",
    "class_1 = []\n",
    "class_2 = []\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,5))\n",
    "fig.suptitle('f1-score')\n",
    "X = np.arange(3)\n",
    "#fig = plt.figure()\n",
    "#ax1 = fig.add_axes([0,0,1,1])\n",
    "color_l = ['b','g', 'y','r','c', 'm', 'k', 'black','purple', 'pink', 'olive', 'gray', 'orange', 'lime']\n",
    "for i in range(np.shape(data)[0]):\n",
    "    ax1.bar(X + 0.05*i, data[i], color = color_l[i], width = 0.05)\n",
    "ax1.set_title('Local Model')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_xticks([0.2,1.2,2.2])\n",
    "#ax1.set_xticks(['High','Low','Medium'])\n",
    "ax1.set_xticklabels(['High','Low','Medium'])\n",
    "#ax1.axhline(y=0.5, color='r', linestyle='-')\n",
    "ax1.set_ylim([0.4, 0.8])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(np.shape(data)[0]):\n",
    "    ax2.bar(X + 0.05*i, data_b[i], color = color_l[i], width = 0.05)\n",
    "ax2.set_title('Global Model')\n",
    "ax2.set_xticklabels(['High','Low','Medium'])\n",
    "#ax2.axhline(y=0.5, color='r', linestyle='-')\n",
    "ax2.set_xticks([0.2,1.2,2.2])\n",
    "ax2.set_ylim([0.4, 0.8])\n",
    "ax.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "41b8dcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_42308/1501618879.py:50: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_xticklabels(['Client 0','Client 1', 'Client 2', 'Client 3', 'Client 4', 'Client 5'])\n",
      "/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_42308/1501618879.py:58: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax3.set_xticklabels(['Client 0','Client 1', 'Client 2', 'Client 3', 'Client 4', 'Client 5'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4, 0.8)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/MAAAFTCAYAAAB1f1xkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjzElEQVR4nO3dfZBlZ30f+O/PI8SLjMEuhjdJA7ItIFAJpBjLpjAB7IBlyi6FNUuEX1icrKfklJxsduOgOImRYy+xQxJYCtixgrUstkFx2RbIWSGB7UhgB1ckOQK9gPCgABqGtVYBAyK8WPJv/+g7+KrVoz5npnv6Pq3Pp6pr7jnnOfc+T7f0rfvte/re6u4AAAAA4/iGnZ4AAAAAMI8yDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgC2SVU9tar+S1V9sar+/k7PBwDYPZR5ANg+/zjJNd39yCQ3VdV/rKrPV9UndnheAMDglHkA2D5PSnLL4vaXklya5Kd3bjp/qapO2ek5AADHT5kHgG1QVb+f5IVJ3lRVdyf5s+7+1SS3Tzz/JVV16+IS/U9X1T9aOnZeVd1YVV+oqo9X1bmL/U+sqiuq6rNVdaiqfmLpnIur6jer6teq6gtJXlVVj6qqX6mqzywe4xeqas+WfiMAgG3ht/IAsA26+3uq6pokv9bdbz2Ou/iVJC/v7g9U1TcnOStJquqcJG9P8rIkv5fkCUkeuTjnnVm7EuCJSZ6W5H1VdXt3/97i+HlJ/sckr0zy0MX4P03y7UlOS/IfktyR5JePY74AwEmkzAPAavrzJE+vqg919+eSfG6x/+8mubS737fY/nSSVNWZSb47yQ9091eS3FhVb03yY1kr/Unywe5+12L8NyX5/iSP7u4vJ/lSVb0+yYEo8wCw8lxmDwA7rKp+pqruXnwdXOz+oSQvSfLJqrq2qp6z2H9mko9vcDdPTPLZ7v7i0r5PJjl9afuOpdtPSvKQJJ+pqj+rqj/LWol/7ImvCADYbl6ZB4Ad1t2vTfLadfuuS3JeVT0kyYVJfiNrRf6OJN+2wd0cSfItVfXIpUK/L4tX7o/e7dLtO5J8NcljuvueLVkIAHDSeGUeAE6CqvqGqnpY1l4Nr6p6WFWdeoyxp1bVj1TVo7r7z5N8Icm9i8O/kuTHq+p7F/d5elU9rbvvSPKfkvzLxX3/taxdkv/rGz1Gd38myXuT/Juq+qbFfX1bVT1/a1cOAGwHZR4ATo6/keTLSa7M2ivmX85amT6WH0vyicU7z1+Q5EeTpLv/c5IfT/L6JJ9Pcm3WLplPklckeXLWXqW/PMlrlv62fiOvTHJqkluz9jf5v5m1N9QDAFZcdffmowAAAICV4ZV5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDLPMKrqlqp6wcSxn6iqv7m9MwIAYLerqq6qb1/cPlhV/3yn5wSJMs8K2aiAV9WrquoPkqS7n9Hd1+zI5ABWnF9iAnw9C79WVY9Zt//GRSl/8oncf3df0N0/f0KThC2izAMAALvJf03yiqMbVfVXkzx856YD20OZZxjLrzpV1cOr6v+uqs9V1Ueq6h9X1eF1pzyrqj5cVZ+vqn9fVQ/bgWkD7JiqemhVvaGqjiy+3lBVD10cu7aqfmhx+7sXr1i9ZLH9N6vqxh2cOsCJ+NUkr1za/p+SvP3oxiIb/3VVfaqq/nRx6fzDl47/dFV9ZpGbf2f5jqvqbVX1C4vbX7+CdOn48iX5b6uqt1TVe6rq7qr6w6p6/CKLP1dVH62qv74N6+dBQplnVK9J8uQk35rkRUl+dIMxL09ybpKzkvy1JK86SXMDWBX/NMl3JXlWkmcmOSfJP1scuzbJCxa3/0aS25M8f2n72pM1SYAt9kdJvqmq/kpV7Unyt5P82tLxX0rylKxl47cnOT3JzyZJVZ2b5B9l7fnl2UlO9M+XXp613H1Mkq8m+WCSP15s/2aSf3uC98+DmDLPqnlXVf3Z0a8kbznGuJcneW13f667Dyd54wZj3tjdR7r7s0l+J2uBDfBg8iNJ/kV339nd/1+Sn0vyY4tj1+a+5f1fLm0/P8o8MLajr86/KMlHk3x6sb+S/ESSf9jdn+3uLyZ5bZLzF8dfnuT/6u6bu/tLSS4+wXlc3t03dPdXklye5Cvd/fbuvjfJv0/ilXmOmzLPqvlb3f3oo19J/t4xxj0xyR1L23dsMOb/Xbr935N849ZMEWAYT0zyyaXtTy72JWuvDj2lqh6XtV92vj3JmYs3jTonyftP4jwBttqvJvnhrF2Z+fal/XuTPCLJDUsvHl212J/c/znmcoYejz9duv3lDbY9P+W4KfOM6jNJzljaPnOnJgKwwo4kedLS9r7FvnT3f09yQ5J/kOTm7v5akv+U5H9N8vHuvuskzxVgy3T3J7P2RngvSfLbS4fuylqJfsbSC0iP6u6jpfozue/zyn0P8DBfytovBpIkVfX4LZk8TKTMM6rfSPJPquqbq+r0JBfu9IQAVsBDquphR7+SvDPJP6uqvYtX3H829/270Wuzlp9HL6m/Zt02wMj+bpLvWVwuf9RfJPl3SV5fVY9Nkqo6vaq+b3H8N5K8qqqeXlWPyNr7NB3Lh5I8o6qetcjci7d8BfAAlHlG9S+SHM7ab1x/N2tvIPLVHZ0RwM67MmuvOB39eliS65N8OMlNWXvTpV9YGn9tkkfmLy+pX78NMKzu/nh3X7/BoVcnOZTkj6rqC1l7LvnUxTnvSfKGJL+/GPP7D3D/H8vac9LfTfInSf7gWGNhO1R37/Qc4IRV1U8mOb+7n7/pYAAAgMF5ZZ4hVdUTquq5VfUNVfXUJP9b1t4hFAAAYNebVOar6tyquq2qDlXVRRscf1RV/U5VfaiqbqmqH596LhynU5P8cpIvZu3yp3fn2B9jBztCdgLMIzcBptv0Mvuq2pPkY1n7jMbDSa5L8oruvnVpzM8keVR3v7qq9ia5Lcnjk9y72bkAu5HsBJhHbgLMM+WV+XOSHOru2xcfW3NZkvPWjekkj6yqytpnJX42yT0TzwXYjWQnwDxyE2CGKWX+9CR3LG0fXuxb9qYkfyVrn117U5J/0N1/MfFcgN1IdgLMIzcBZjhlwpjaYN/6a/O/L8mNSb4nybcleV9VfWDiuWsPUnUgyYEkOe200579tKc9bcLU5rnhyA2bjnn2E5+95Y8LrIYbbrjhru7ee5Iebtuz82TkJvDgtttyM5GdwPY7Wdk5pcwfTnLm0vYZWftt6LIfT/KLvfYH+Ieq6r8medrEc5Mk3X1JkkuSZP/+/X399Rt9JOSJqZ/bKOfv6/rXbP3jAquhqj55Eh9u27PzZOQm8OC223IzkZ3A9jtZ2TnlMvvrkpxdVWdV1alJzk9yxboxn0ryvUlSVY9L8tQkt088F2A3kp0A88hNgBk2fWW+u++pqguTXJ1kT5JLu/uWqrpgcfxgkp9P8raquilrlzm9urvvSpKNzt2epQCsDtkJMI/cBJhnymX26e4rk1y5bt/BpdtHkrx46rkADwayE2AeuQkw3ZTL7AEAAIAVoswDAADAYJR5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAxGmQcAAIDBKPMAAAAwGGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGM6nMV9W5VXVbVR2qqos2OP7TVXXj4uvmqrq3qr5lcewTVXXT4tj1W70AgFUlOwHmkZsA052y2YCq2pPkzUlelORwkuuq6oruvvXomO5+XZLXLcb/YJJ/2N2fXbqbF3b3XVs6c4AVJjsB5pGbAPNMeWX+nCSHuvv27v5aksuSnPcA41+R5J1bMTmAgclOgHnkJsAMU8r86UnuWNo+vNh3P1X1iCTnJvmtpd2d5L1VdUNVHTjeiQIMRnYCzCM3AWbY9DL7JLXBvj7G2B9M8ofrLnd6bncfqarHJnlfVX20u99/vwdZC90DSbJv374J0wJYaduenXIT2GU85wSYYcor84eTnLm0fUaSI8cYe37WXe7U3UcW/96Z5PKsXUJ1P919SXfv7+79e/funTAtgJW27dkpN4FdxnNOgBmmlPnrkpxdVWdV1alZC88r1g+qqkcleX6Sdy/tO62qHnn0dpIXJ7l5KyYOsOJkJ8A8chNghk0vs+/ue6rqwiRXJ9mT5NLuvqWqLlgcP7gY+tIk7+3uLy2d/rgkl1fV0cd6R3dftZULAFhFshNgHrkJME91H+tPkXbO/v37+/rrt/7jQevnNvpTrPvq16ze9wPYGlV1Q3fv3+l5bIftyk3gwW0352YiO4HtcbKyc8pl9gAAAMAKUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMJjdUearpn0BAADALrA7yjwAAAA8iCjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAzmlJ2ewINe1bRhF28+pl/TJzYXAAAAhuCVeQAAABiMMg8AAACDmVTmq+rcqrqtqg5V1UUbHP/pqrpx8XVzVd1bVd8y5VyA3Up2AswjNwGm27TMV9WeJG9O8v1Jnp7kFVX19OUx3f267n5Wdz8ryT9Jcm13f3bKuQC7kewEmEduAswz5Q3wzklyqLtvT5KquizJeUluPcb4VyR553GeC2zGmyaOQnYCzCM3AWaYUuZPT3LH0vbhJN+50cCqekSSc5NcOPdcBqRUwgORnQDzyE2AGaaU+Y0a27Ga1w8m+cPu/uzcc6vqQJIDSbJv374J04IT4BcRbL9tz065CewynnMCzDDlDfAOJzlzafuMJEeOMfb8/OXlTrPO7e5Lunt/d+/fu3fvhGkBrLRtz065CewynnMCzDClzF+X5OyqOquqTs1aeF6xflBVPSrJ85O8e+65ALuQ7ASYR24CzLDpZfbdfU9VXZjk6iR7klza3bdU1QWL4wcXQ1+a5L3d/aXNzt3qRQCsGtkJMI/cBJhnyt/Mp7uvTHLlun0H122/LcnbppwL8GAgOwHmkZsA0025zB4AAABYIco8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGMykz5kH2BJVmw+5eNpd9Wv6xOYCAAAD88o8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAxmUpmvqnOr6raqOlRVFx1jzAuq6saquqWqrl3a/4mqumlx7PqtmjjAqpOdAPPITYDpTtlsQFXtSfLmJC9KcjjJdVV1RXffujTm0UnekuTc7v5UVT123d28sLvv2rppA6w22Qkwj9wEmGfKK/PnJDnU3bd399eSXJbkvHVjfjjJb3f3p5Kku+/c2mkCDEd2AswjNwFmmFLmT09yx9L24cW+ZU9J8s1VdU1V3VBVr1w61kneu9h/4MSmCzAM2Qkwj9wEmGHTy+yT1Ab7eoP7eXaS703y8CQfrKo/6u6PJXludx9ZXAb1vqr6aHe//34Psha6B5Jk3759c9YAsIq2PTvlJrDLeM4JMMOUV+YPJzlzafuMJEc2GHNVd39p8XdK70/yzCTp7iOLf+9McnnWLqG6n+6+pLv3d/f+vXv3zlsFwOrZ9uyUm8Au4zknwAxTyvx1Sc6uqrOq6tQk5ye5Yt2Ydyd5XlWdUlWPSPKdST5SVadV1SOTpKpOS/LiJDdv3fQBVpbsBJhHbgLMsOll9t19T1VdmOTqJHuSXNrdt1TVBYvjB7v7I1V1VZIPJ/mLJG/t7pur6luTXF5VRx/rHd191XYtBmBVyE6AeeQmwDxT/mY+3X1lkivX7Tu4bvt1SV63bt/tWVz6BPBgIzsB5pGbANNNucweAAAAWCHKPAAAAAxGmQcAAIDBKPMAAAAwGGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDCTynxVnVtVt1XVoaq66BhjXlBVN1bVLVV17ZxzAXYj2Qkwj9wEmO6UzQZU1Z4kb07yoiSHk1xXVVd0961LYx6d5C1Jzu3uT1XVY6eeC7AbyU6AeeQmwDxTXpk/J8mh7r69u7+W5LIk560b88NJfru7P5Uk3X3njHMBdiPZCTCP3ASYYUqZPz3JHUvbhxf7lj0lyTdX1TVVdUNVvXLGuQC7kewEmEduAsyw6WX2SWqDfb3B/Tw7yfcmeXiSD1bVH008d+1Bqg4kOZAk+/btmzAtgJW27dkpN4FdxnNOgBmmvDJ/OMmZS9tnJDmywZiruvtL3X1XkvcneebEc5Mk3X1Jd+/v7v179+6dOn+AVbXt2Sk3gV3Gc06AGaaU+euSnF1VZ1XVqUnOT3LFujHvTvK8qjqlqh6R5DuTfGTiuQC7kewEmEduAsyw6WX23X1PVV2Y5Ooke5Jc2t23VNUFi+MHu/sjVXVVkg8n+Yskb+3um5Nko3O3aS0AK0N2AswjNwHmmfI38+nuK5NcuW7fwXXbr0vyuinnAjwYyE6AeeQmwHRTLrMHAAAAVogyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAxGmQcAAIDBKPMAAAAwGGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGMykMl9V51bVbVV1qKou2uD4C6rq81V14+LrZ5eOfaKqblrsv34rJw+wymQnwDxyE2C6UzYbUFV7krw5yYuSHE5yXVVd0d23rhv6ge7+gWPczQu7+64TmyrAOGQnwDxyE2CeKa/Mn5PkUHff3t1fS3JZkvO2d1oAw5OdAPPITYAZppT505PcsbR9eLFvvedU1Yeq6j1V9Yyl/Z3kvVV1Q1UdOIG5AoxEdgLMIzcBZtj0MvsktcG+Xrf9x0me1N13V9VLkrwrydmLY8/t7iNV9dgk76uqj3b3++/3IGuheyBJ9u3bN3X+AKtq27NTbgK7jOecADNMeWX+cJIzl7bPSHJkeUB3f6G7717cvjLJQ6rqMYvtI4t/70xyedYuobqf7r6ku/d39/69e/fOXgjAitn27JSbwC7jOSfADFPK/HVJzq6qs6rq1CTnJ7lieUBVPb6qanH7nMX9/reqOq2qHrnYf1qSFye5eSsXALCiZCfAPHITYIZNL7Pv7nuq6sIkVyfZk+TS7r6lqi5YHD+Y5GVJfrKq7kny5STnd3dX1eOSXL7I3FOSvKO7r9qmtQCsDNkJMI/cBJhnyt/MH72M6cp1+w4u3X5TkjdtcN7tSZ55gnMEGJLsBJhHbgJMN+UyewAAAGCFKPMAAAAwGGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAxGmQcAAIDBTCrzVXVuVd1WVYeq6qINjr+gqj5fVTcuvn526rkAu5XsBJhHbgJMd8pmA6pqT5I3J3lRksNJrquqK7r71nVDP9DdP3Cc5wLsKrITYB65CTDPlFfmz0lyqLtv7+6vJbksyXkT7/9EzgUYmewEmEduAswwpcyfnuSOpe3Di33rPaeqPlRV76mqZ8w8F2C3kZ0A88hNgBk2vcw+SW2wr9dt/3GSJ3X33VX1kiTvSnL2xHPXHqTqQJIDSbJv374J0wJYaduenXIT2GU85wSYYcor84eTnLm0fUaSI8sDuvsL3X334vaVSR5SVY+Zcu7SfVzS3fu7e//evXtnLAFgJW17dspNYJfxnBNghill/rokZ1fVWVV1apLzk1yxPKCqHl9Vtbh9zuJ+/9uUcwF2KdkJMI/cBJhh08vsu/ueqrowydVJ9iS5tLtvqaoLFscPJnlZkp+sqnuSfDnJ+d3dSTY8d5vWArAyZCfAPHITYJ4pfzN/9DKmK9ftO7h0+01J3jT1XIAHA9kJMI/cBJhuymX2AAAAwApR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAxGmQcAAIDBKPMAAAAwGGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGIwyDwAAAIOZVOar6tyquq2qDlXVRQ8w7juq6t6qetnSvk9U1U1VdWNVXb8VkwYYgewEmEduAkx3ymYDqmpPkjcneVGSw0muq6oruvvWDcb9UpKrN7ibF3b3XVswX4AhyE6AeeQmwDxTXpk/J8mh7r69u7+W5LIk520w7qeS/FaSO7dwfgCjkp0A88hNgBmmlPnTk9yxtH14se/rqur0JC9NcnCD8zvJe6vqhqo6cLwTBRiM7ASYR24CzLDpZfZJaoN9vW77DUle3d33Vt1v+HO7+0hVPTbJ+6rqo939/vs9yFroHkiSffv2TZgWwErb9uyUm8Au4zknwAxTXpk/nOTMpe0zkhxZN2Z/ksuq6hNJXpbkLVX1t5Kku48s/r0zyeVZu4Tqfrr7ku7e39379+7dO2cNAKto27NTbgK7jOecADNMKfPXJTm7qs6qqlOTnJ/kiuUB3X1Wdz+5u5+c5DeT/L3ufldVnVZVj0ySqjotyYuT3LylKwBYTbITYB65CTDDppfZd/c9VXVh1t4xdE+SS7v7lqq6YHF8o79ZOupxSS5fXAZ1SpJ3dPdVJz5tgNUmOwHmkZsA80z5m/l095VJrly3b8NA7e5XLd2+PckzT2B+AMOSnQDzyE2A6aZcZg8AAACsEGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMMo8AAAADEaZBwAAgMEo8wAAADAYZR4AAAAGo8wDAADAYJR5AAAAGIwyDwAAAINR5gEAAGAwyjwAAAAMRpkHAACAwSjzAAAAMBhlHgAAAAajzAMAAMBglHkAAAAYjDIPAAAAg1HmAQAAYDDKPAAAAAxGmQcAAIDBKPMAAAAwmEllvqrOrarbqupQVV30AOO+o6ruraqXzT0XYLeRnQDzyE2A6TYt81W1J8mbk3x/kqcneUVVPf0Y434pydVzzwXYbWQnwDxyE2CeKa/Mn5PkUHff3t1fS3JZkvM2GPdTSX4ryZ3HcS7AbiM7AeaRmwAzTCnzpye5Y2n78GLf11XV6UlemuTg3HMBdinZCTCP3ASY4ZQJY2qDfb1u+w1JXt3d91bdZ/iUc9cGVh1IcmCxeXdV3TZhbg/kMUnuus+eizc/qS7eaMonnbnvDHPfGfed+8XTTjrOuT/peE46Ttuenety86tVdfNxzHMU9/9vfHexvrHt5vU99SQ+1k4855SdY7O+ce3mtSUnKTunlPnDSc5c2j4jyZF1Y/YnuWwRqo9J8pKqumfiuUmS7r4kySXTpr25qrq+u/dv1f2dTOa+M8x9Z4w8901se3Yu5+Yu/j4msb7RWd+4qur6k/hwJ/05527+2SXWN7rdvL7dvLbk5GXnlDJ/XZKzq+qsJJ9Ocn6SH14e0N1nHb1dVW9L8h+6+11Vdcpm5wLsUrITYB65CTDDpmW+u++pqguz9o6he5Jc2t23VNUFi+Pr/2Zp03O3ZuoAq0t2AswjNwHmmfLKfLr7yiRXrtu3YaB296s2O/ck2bJL9neAue8Mc98ZI8/9AZ3k7Ny138cF6xub9Y3rpK5tB55z7uafXWJ9o9vN69vNa0tO0vqqe8P3BgEAAABW1JSPpgMAAABWyMqV+ap6fFVdVlUfr6pbq+rKqnpKVT356EeHVNX+qnrjCTzGzzzAsWdX1U1Vdaiq3ljrPvdkxef+v1fVHVV193Hc747NvaoeUVX/T1V9tKpuqapfHGXui2NXVdWHFnM/WFV7Rpn70pgr5n40z07PvaquqarbqurGxddjj/dxdtIKfB+PO/MmPvZOr++4c3HiYw+bnRMfe6d/fsedrxMed9j8nfjYO/2z29aMXoH1yc4TsJuzcwV+dtuWm4v7l52rlJ3dvTJfWfuM0A8muWBp37OSPC/Jk5PcvEWPc/cDHPvPSZ6zmMt7knz/QHP/riRPeKAxqzj3JI9I8sLF7VOTfGCw7/s3Lc3lt5KcP8rcF8f/hyTvmPN4qzD3JNck2b8Vj7NTXyvyfTyuzBtofceViyOs70Syc4T1LY4dV76OsLbF8dn5O8r6tjOjV2R9snPQ9W1ndu702hbHtiU3V2V9i+Oy8+j4rfwGbMHCvifJ+49x7OvfwCQvyNpHkSTJaUkuzdrHmfyXJOct9r8qyW8nuSrJnyT5V4v9v5jk3iQ3Jvn1dY/xhCQfXdp+RZJfHmHuU/8DWfW5L8b+H0l+YrS5J3lIkt9J8rdHmXuSb0zyB0mennllfhXmfk3GL/PDZt4I61v3eNvxhHRl1rcYOzk7R1tfZubrCGvLcebvQOu7JttX5mXnNv/8lh5Pdg66tmxxbq7K+iI77zt+K78BW/AN/PtJXj/zG/jaJD+6uP3oJB9bfFNfleT2JI9K8rAkn0xy5mLcsX5Ttz/J7y5tP+/o46z63Nc93twyv0pzf/Ti/G8dae5Z+yicz2Xtt4R7Rpl7ktcneWlm/rZxReZ+TZKbshaG/zyLN/Qc6Wunv485gcwbYX3rHm87npCu0voenRnZOdL6chz5OsLacpz5O9D6rsk2ZfROry+yczet79HZwuxclbVlG3JzVdYX2Xmfr5X7m/nj8OIkF1XVjVlb/MOS7Fsc+73u/nx3fyXJrUmetMl9bfT3Tr1F89zIVs79ZNvyuVfVKUnemeSN3X37ls/4L2353Lv7+7L2m/qHZu23ettly+ZeVc9K8u3dffm2zfa+tvr7/iPd/Vez9iTqeUl+bMtnvJpGzrwpRs7FKUbOzilGztfNjJy/U+z2jJadsvM+Vig7d3NuJrJzW7Nz0ufMn0S3JHnZzHMqyQ9192332Vn1nUm+urTr3my+3sNJzljaPiPJkYnz2Om5n4hVmfslSf6ku98wYx6rMvd091eq6ook5yV534RTdnruz0ny7Kr6xGLsY6vqmu5+wYR57PTc092fXvz7xap6R5Jzkrx95px22k5/H08k86bY6fVtt1VZ3/Fk5xSrsr7jydfN7PTaTiR/p9jp9W13Ru/0+mTniVmV9W1Hdq7K2rYjN5OdX5/sXGfVXpn//SQPraqfOLqjqr6jqp7/AOdcneSnqtbeRbSq/vqEx/nzqnrI+p3d/ZkkX6yq71rc3yuTvHuEuZ+gHZ97Vf1C1i5D+V8mz3rNjs69qr6xqp6wuH1Kkpck+egIc+/u/7O7n9jdT07y3Uk+NiMMd/r7fkpVPWZx+yFJfiDJlr+j6Umw0/8NnEjmTbHj2bLNdnx9J5CdU+z0/+cnkq+b2en/904kf6fY6Z/ddmf0Tv/8ZOeJ2fH1bWN27vT/e9uZm8nO/78nO9dZqTLfa38o8NIkL6q1jwO4JcnFeeDfdv581t7g4cO19nEBPz/hoS5ZjP/1DY79ZJK3JjmU5ONZe4fSIeZeVf+qqg4neURVHa6qi0eYe1WdkeSfZu2NLP641j6G4X8eYe5Z+5uYK6rqw0k+lOTOJAcHmftxW4G5PzTJ1Yvv+41JPp3k381axApYge9jcpyZN8UqrO94c3GKnV7fiWTnFDu9vpxAvm5mBda2rVZgfdua0SuwvkR2HredXt92ZudOry3bmJvJSqxvW63A+mZnZ63NGQAAABjFSr0yDwAAAGxOmQcAAIDBKPMAAAAwGGUeAAAABqPMAwAAwGCUeQAAABiMMg8AAACDUeYBAABgMP8/q/wmg9Me47EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1224x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "local = np.array([[0.72416771, 0.78731464, 0.52320393],\n",
    " [0.71057333, 0.7848602,  0.51432353],\n",
    " [0.70155356, 0.78050222, 0.52336165],\n",
    " [0.70031546, 0.77649909, 0.49657827],\n",
    " [0.70317175, 0.76688742, 0.48577525],\n",
    " [0.68265554, 0.76648352, 0.49356396]])\n",
    "\n",
    "glob = np.array([[0.92416771, 0.78731464, 0.52320393],\n",
    " [0.71057333, 0.7848602,  0.51432353],\n",
    " [0.70155356, 0.78050222, 0.52336165],\n",
    " [0.70031546, 0.77649909, 0.49657827],\n",
    " [0.70317175, 0.76688742, 0.48577525],\n",
    " [0.68265554, 0.76648352, 0.49356396]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2e496efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7s/lxjghsr57nscy448l9t3l2800000gq/T/ipykernel_42308/2304578735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_T\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Local Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "for i in range(np.shape(local_T)[1]):\n",
    "    print(i)\n",
    "\n",
    "    ax1.bar(X + 0.05*i, local_T[0,i], color = color_l[i], width = 0.05)\n",
    "ax1.set_title('Local Model')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_xticks([0.2,1.2,2.2])\n",
    "#ax1.set_xticks(['High','Low','Medium'])\n",
    "ax1.set_xticklabels(['High','Low','Medium'])\n",
    "#ax1.axhline(y=0.5, color='r', linestyle='-')\n",
    "ax1.set_ylim([0.4, 0.8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0e403dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72416771 0.71057333 0.70155356 0.70031546 0.70317175 0.68265554]\n"
     ]
    }
   ],
   "source": [
    "print(local_T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb1469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
